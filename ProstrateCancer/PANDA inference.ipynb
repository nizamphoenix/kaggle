{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Description\nThis kernel performs inference for [PANDA concat tile pooling starter](https://www.kaggle.com/iafoss/panda-concat-fast-ai-starter) kernel with use of multiple models and 8 fold TTA. Check it for more training details. The image preprocessing pipline is provided [here](https://www.kaggle.com/iafoss/panda-16x128x128-tiles).   \n\n[All resnet pretrained weights](https://www.kaggle.com/ar90ngas/timm-pretrained-resnet)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport fastai\nfrom fastai.vision import *\nimport os\nfrom mish_activation import *\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nsys.path.insert(0, '../input/semisupervised-imagenet-models/semi-supervised-ImageNet1K-models-master/')\nfrom hubconf import *\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA   = '../input/prostate-cancer-grade-assessment/train_images'\nTEST   = '../input/prostate-cancer-grade-assessment/train.csv'\nSAMPLE = '../input/prostate-cancer-grade-assessment/sample_submission.csv'\nMODELS = [f'../input/panda-training/RNXT50_{i}.pth' for i in range(4)]\n#MODELS = [f'../input/panda-starter-models/RNXT50_{i}.pth' for i in range(4)]#original\n\n\nsz = 128\nbs = 2\nN = 12\nnworkers = 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\ndef get_resnext(layers, pretrained, progress, **kwargs):\n    from torchvision.models.resnet import ResNet, Bottleneck\n    model = ResNet(Bottleneck, layers, **kwargs)\n    model.load_state_dict(torch.load('../input/resnext-50-ssl/semi_supervised_resnext50_32x4-ddb3e555.pth'))\n    return model\n\n\nclass GleasonModel(nn.Module):\n    def __init__(self, n=4):\n        super().__init__()\n        #Set pretrained to False\n        m = get_resnext([3, 4, 6, 3], pretrained=False, progress=False, groups=32,width_per_group=4)\n        self.enc = nn.Sequential(*list(m.children())[:-2])       \n        nc = list(m.children())[-1].in_features\n        self.head = nn.Sequential(AdaptiveConcatPool2d(),\n                                  Flatten(),\n                                  nn.Linear(2*nc,512),\n                                  Mish(),\n                                  nn.BatchNorm1d(512), \n                                  nn.Dropout(0.5),\n                                  nn.Linear(512,256),\n                                  Mish(),\n                                  nn.BatchNorm1d(256), \n                                  nn.Dropout(0.3))\n        self.prim =  nn.Linear(256,n)\n        self.sec  =  nn.Linear(256,n)\n      \n\n        \n    def forward(self, *x):\n        shape = x[0].shape\n        n = shape[1]# no_of_tiles\n        x = x[0].view(-1,shape[2],shape[3],shape[4])\n        #x: [192, 3, 128, 128]\n        x = self.enc(x)\n        #x: (bs*8*n) x C x 4 x 4 = 192, 2048, 4, 4\n        #bs*8 because of p.view(bs,8*len(models),-1)--see below\n        shape = x.shape\n        #concatenate the output for tiles into a single map\n        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n        #x: (bs*8) x C x (n*4) x 4 = 16, 2048, 48, 4\n        x = self.head(x)\n        prim_gleason = self.prim(x)\n        sec_gleason  = self.sec(x)\n        preds = [prim_gleason,sec_gleason]\n        return preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113/5  \nhttps://discuss.pytorch.org/t/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict/1686/3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nfor path in MODELS:\n    print(path)\n    model = GleasonModel()\n    model_dict = model.state_dict()\n    pretrained_dict = torch.load(path,map_location=torch.device('cpu'))\n    # 1. filter out unnecessary keys\n    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n    # 2. overwrite entries in the existing state dict\n    model_dict.update(pretrained_dict) \n    # 3. load the new state dict\n    model.load_state_dict(model_dict)\n    model.float()\n    model.eval()\n    model.cuda()\n    models.append(model)\n    \ndel pretrained_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def tile_high_res(fname):\n    import gc\n    N = 16\n    sz= 256\n    import openslide\n    # use layer 2 for tile selection\n    img = skimage.io.MultiImage(fname)[-1]\n    shape = img.shape\n    r = 16 # ratio of layer 0 vs layer 2 res\n    sz16 = sz//r\n    pad0,pad1 = (sz16 - shape[0]%sz16)%sz16, (sz16 - shape[1]%sz16)%sz16\n    img  = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n    img  = img.reshape(img.shape[0]//sz16,sz16,img.shape[1]//sz16,sz16,3)\n    img  = img.transpose(0,2,1,3,4).reshape(-1,sz16,sz16,3)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:min(N,len(img))]\n    del img\n    gc.collect()\n    # read layer 0 tile by tile with use of openslide\n    n0,n1 = (pad0+shape[0])//sz16, (pad1+shape[1])//sz16\n    img0  = openslide.OpenSlide(fname)\n    tiles = []\n    for idx in idxs:\n        x = (-pad0//2 + sz16*(idx//n1))*r\n        y = (-pad1//2 + sz16*(idx%n1))*r\n        t = np.array(img0.read_region((y,x),0,(sz,sz)))[:,:,:3]\n        tiles.append(t)\n    del img0\n    gc.collect()\n    for i in range(N - len(tiles)): \n        tiles.append(np.full((sz,sz,3), 255, dtype=np.uint8))\n#     result = []\n#     for i in range(len(tiles)):\n#         result.append({'img':tiles[i],'idx':i})\n#     del tiles\n#     gc.collect()\n#     return result\n    return np.stack(tiles)\nmean = torch.tensor([1-0.68688968,1-0.44634704,1-0.61367611])\nstd = torch.tensor([0.46521431,0.46922062,0.42265951])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tile(img):\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\nmean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\nstd  = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n\nclass PandaDataset(Dataset):\n    def __init__(self, path, test):\n        self.path = path\n        self.names = list(pd.read_csv(test).image_id)\n\n    def __len__(self):\n        return len(self.names)\n\n    def __getitem__(self, idx):\n        name = self.names[idx]\n        img = skimage.io.MultiImage(os.path.join(DATA,name+'.tiff'))[-1]\n        tiles = torch.Tensor(1.0 - tile_high_res(img)/255.0)\n        tiles = (tiles - mean)/std\n        return tiles.permute(0,3,1,2), name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_isup_preds(preds):\n    '''\n    converts gleason scores predicted by the model to isup_grades.\n    returns a torch tensor of isup_preds\n    '''\n    lookup_map  = {(0,0):0,(1,1):1,(1,2):2,(2,1):3,(2,2):4,(3,1):4,(1,3):4,(2,3):5,(3,2):5,(3,3):5}\n    lookup_map2 = {(0,1):1,(0,2):1,(0,3):2,(1,0):1,(2,0):3,(3,0):4}\n    \n    prim_preds = torch.stack([preds[0][0],preds[1][0],preds[2][0],preds[3][0]],dim=1)\n    prim_preds = prim_preds.view(bs,8*len(models),-1).mean(dim=1).argmax(-1).cpu()#shape=2\n    sec_preds  = torch.stack([preds[0][1],preds[1][1],preds[2][1],preds[3][1]],dim=1)\n    sec_preds  = sec_preds.view(bs,8*len(models),-1).mean(dim=1).argmax(-1).cpu()#shape=2\n    \n    temp_preds = torch.cat([prim_preds.view(2,1),sec_preds.view(2,1)],dim=1)\n    temp = []\n    count = 0\n    errors = 0\n    for i in np.array(temp_preds.cpu()):\n        count+=1\n        try:\n            temp.append(lookup_map[tuple(i)])\n        except KeyError:\n            errors+=1\n            temp.append(lookup_map2[tuple(i)])\n    print(\"count={0},errors={1}\".format(count,errors),\",correct=\",count-errors)\n    isup_preds = torch.tensor(temp,dtype=torch.long,device='cpu')\n    return isup_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(SAMPLE)\nlookup_map  = {(0,0):0,(1,1):1,(1,2):2,(2,1):3,(2,2):4,(3,1):4,(1,3):4,(2,3):5,(3,2):5,(3,3):5}\nlookup_map2 = {(0,1):1,(0,2):1,(0,3):2,(1,0):1,(2,0):3,(3,0):4}\nif os.path.exists(DATA):\n    print(\"Predicting....\")\n    ds = PandaDataset(DATA,TEST)\n    dl = DataLoader(ds, batch_size=bs, num_workers=nworkers, shuffle=False)\n    names,preds = [],[]\n    with torch.no_grad():\n        for imgs,filenames in tqdm(dl):\n            imgs = imgs.cuda()\n            #dihedral TTA\n            imgs = torch.stack([imgs,imgs.flip(-1),imgs.flip(-2),imgs.flip(-1,-2),\n                         imgs.transpose(-1,-2),imgs.transpose(-1,-2).flip(-1),\n                        imgs.transpose(-1,-2).flip(-2),imgs.transpose(-1,-2).flip(-1,-2)],dim=1)\n            imgs = imgs.view(-1,N,3,sz,sz)\n        \n            all_preds = [model(imgs) for model in models]\n            p=get_isup_preds(all_preds)#for 2(bs) images only\n            \n            names.append(filenames)\n            preds.append(p)\n    names = np.concatenate(names)\n    preds = torch.cat(preds).numpy()\n    sub_df = pd.DataFrame({'image_id': names, 'isup_grade': preds})\n    sub_df.to_csv('submission.csv', index=False)\n    sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df[['isup_grade']].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def _resnext(url, block, layers, pretrained, progress, **kwargs):\n#     model = ResNet(block, layers, **kwargs)\n#     #state_dict = load_state_dict_from_url(url, progress=progress)\n#     #model.load_state_dict(state_dict)\n#     return model\n\n# class Model(nn.Module):\n#     def __init__(self, arch='resnext50_32x4d', n=6, pre=True):\n#         super().__init__()\n#         #m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n#         m = _resnext(semi_supervised_model_urls[arch], Bottleneck, [3, 4, 6, 3], False, \n#                 progress=False,groups=32,width_per_group=4)\n#         self.enc = nn.Sequential(*list(m.children())[:-2])       \n#         nc = list(m.children())[-1].in_features\n#         self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n#                 Mish(),nn.BatchNorm1d(512),nn.Dropout(0.5),nn.Linear(512,n))\n        \n#     def forward(self, x):\n#         shape = x.shape\n#         n = shape[1]\n#         x = x.view(-1,shape[2],shape[3],shape[4])\n#         x = self.enc(x)\n#         shape = x.shape\n#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n#         x = self.head(x)\n#         return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# models = []\n# for path in MODELS:\n#     state_dict = torch.load(path,map_location=torch.device('cpu'))\n#     model = Model()\n#     model.load_state_dict(state_dict)\n#     model.float()\n#     model.eval()\n#     model.cuda()\n#     models.append(model)\n\n# del state_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def tile(img):\n#     shape = img.shape\n#     pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n#     img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n#                  constant_values=255)\n#     img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n#     img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n#     if len(img) < N:\n#         img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n#     idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n#     img = img[idxs]\n#     return img\n\n# mean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\n# std = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n\n# class PandaDataset(Dataset):\n#     def __init__(self, path, test):\n#         self.path = path\n#         self.names = list(pd.read_csv(test)[:10].image_id)\n\n#     def __len__(self):\n#         return len(self.names)\n\n#     def __getitem__(self, idx):\n#         name = self.names[idx]\n#         img = skimage.io.MultiImage(os.path.join(DATA,name+'.tiff'))[-1]\n#         tiles = torch.Tensor(1.0 - tile(img)/255.0)\n#         tiles = (tiles - mean)/std\n#         return tiles.permute(0,3,1,2), name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub_df = pd.read_csv(SAMPLE)\n# if os.path.exists(DATA):\n#     ds = PandaDataset(DATA,TEST)\n#     dl = DataLoader(ds, batch_size=bs, num_workers=nworkers, shuffle=False)\n#     names,preds = [],[]\n\n#     with torch.no_grad():\n#         for x,y in tqdm(dl):\n#             x = x.cuda()\n#             #dihedral TTA\n#             x = torch.stack([x,\n#                              x.flip(-1),\n#                              x.flip(-2),\n#                              x.flip(-1,-2),\n#                              x.transpose(-1,-2),\n#                              x.transpose(-1,-2).flip(-1),\n#                              x.transpose(-1,-2).flip(-2),\n#                              x.transpose(-1,-2).flip(-1,-2)],dim=1)#8 TTAs\n#             x = x.view(-1,N,3,sz,sz)\n            \n#             p = [model(x) for model in models]#len=4,16x6 each model(x)\n            \n#             p = torch.stack(p,dim=1)#16x4x6\n#             p = p.view(bs,8*len(models),-1).mean(dim=1).argmax(dim=-1).cpu()#2x1\n            \n\n#             names.append(y)\n#             preds.append(p)\n#             break\n    \n#     names = np.concatenate(names)\n#     preds = torch.cat(preds).numpy()\n#     sub_df = pd.DataFrame({'image_id': names, 'isup_grade': preds})\n#     sub_df.to_csv('submission.csv', index=False)\n#     sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}