{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.61'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "import os\n",
    "from myutils import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "import warnings\n",
    "from squeeze import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d nizamuddin/panda-generating-data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip panda-16x128x128-tiles-data.zip -d ./panda-16x128x128-tiles-data > /dev/null\n",
    "# !rm -rf ./panda-16x128x128-tiles-data/masks\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./cache\n",
    "!rm -rf ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##remove this cell if run locally\n",
    "# !rm -rf ./cache\n",
    "# !mkdir 'cache'\n",
    "# !mkdir 'cache/torch'\n",
    "# !mkdir 'cache/torch/checkpoints'\n",
    "# !cp './se-resnext-weights/sese_resnext101_32x4d-3b2fe3d8.pth' 'cache/torch/checkpoints/'\n",
    "# torch.hub.DEFAULT_CACHE_DIR = 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128\n",
    "bs = 32\n",
    "nfolds = 4\n",
    "SEED = 2020\n",
    "N = 12 #number of tiles per image\n",
    "TRAIN = './panda-16x128x128-tiles-data/train/'\n",
    "LABELS = './train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data  \n",
    "Use stratified KFold split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #>>>>>>>>>>IDEMPOTENT<<<<<<<<<<<<<<<<<<<<\n",
    "# df = pd.read_csv(LABELS).set_index('image_id')\n",
    "# susp = pd.read_csv('PANDA_Suspicious_Slides.csv')\n",
    "# #['marks', 'No Mask', 'Background only', 'No cancerous tissue but ISUP Grade > 0', 'tiss', 'blank']\n",
    "# to_drop = susp.query(\"reason in ['No Mask','No cancerous tissue but ISUP Grade > 0']\")['image_id']\n",
    "# print(\"All indices={0} | Bad indices={1} | Good indices used further={2}\".format(df.shape[0],len(to_drop),len(list(set(df.index)-set(to_drop)))))\n",
    "\n",
    "# import glob\n",
    "# img_list = sorted(glob.glob(os.path.join(TRAIN, '*.png')))\n",
    "# to_drop_temp=[]\n",
    "# for file in to_drop:\n",
    "#     for i in range(0,16):\n",
    "#         myfile = TRAIN+file+'_{0}.png'.format(i)\n",
    "#         to_drop_temp.append(myfile)\n",
    "# to_drop_fullnames = list(set(img_list).intersection(set(to_drop_temp)))\n",
    "# print(len(to_drop_fullnames))\n",
    "# import os\n",
    "# count=0\n",
    "# err=0\n",
    "# for file in to_drop_fullnames:\n",
    "#     try:\n",
    "#         if os.path.isfile(file):\n",
    "#             os.remove(file)\n",
    "#             count+=1\n",
    "#     except: \n",
    "#         err+=1\n",
    "#         print(\"Error: %s file not found\" % myfile)\n",
    "# print(count,err)\n",
    "# #Simple snippet to make sense\n",
    "# makingsense = []\n",
    "# for file in to_drop_fullnames:\n",
    "#     makingsense.append(os.path.isfile(file))\n",
    "# sum(makingsense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering bad images: (9954, 3)\n",
      "\n",
      ">>>>>>>>>Before sampling<<<<<<<<<<<<< (9954, 7)\n",
      "isup grade: 0 | n_instances: 2843 | corresponding gleason score: ['0+0']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 1 | n_instances: 2488 | corresponding gleason score: ['3+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 2 | n_instances: 1258 | corresponding gleason score: ['3+4' '4+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 3 | n_instances: 1122 | corresponding gleason score: ['4+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 4 | n_instances: 1151 | corresponding gleason score: ['4+4' '5+3' '3+5']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 5 | n_instances: 1092 | corresponding gleason score: ['4+5' '5+4' '5+5']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>>>After Balancing data manually by selecting first 1200 from isup_grades 0 and 1<<<<<<<<<<<<< (7023, 7)\n",
      "isup grade: 0 | n_instances: 1200 | corresponding gleason score: ['0+0']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 1 | n_instances: 1200 | corresponding gleason score: ['3+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 2 | n_instances: 1258 | corresponding gleason score: ['3+4' '4+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 3 | n_instances: 1122 | corresponding gleason score: ['4+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 4 | n_instances: 1151 | corresponding gleason score: ['4+4' '5+3' '3+5']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 5 | n_instances: 1092 | corresponding gleason score: ['4+5' '5+4' '5+5']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>>>After sampling<<<<<<<<<< (5000, 7)\n",
      "isup grade: 0 | n_instances: 842 | corresponding gleason score: ['0+0']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 1 | n_instances: 857 | corresponding gleason score: ['3+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 2 | n_instances: 896 | corresponding gleason score: ['3+4' '4+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 3 | n_instances: 791 | corresponding gleason score: ['4+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 4 | n_instances: 817 | corresponding gleason score: ['4+4' '3+5' '5+3']\n",
      "--------------------------------------------------------------------------------\n",
      "isup grade: 5 | n_instances: 797 | corresponding gleason score: ['4+5' '5+5' '5+4']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>split</th>\n",
       "      <th>prim_gleason</th>\n",
       "      <th>secon_gleason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49621f6f666d1c54b23d1616ac4beb72</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab4a7247e87d9cd8b7106a64b3dda927</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>4+5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6468063d0445cf082716fa830a507de2</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2545fbd121c537ccb04c90cef91631c</td>\n",
       "      <td>radboud</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16e1c7937dc0a2394bf82f863dd1a25f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  49621f6f666d1c54b23d1616ac4beb72    karolinska           1           3+3   \n",
       "1  ab4a7247e87d9cd8b7106a64b3dda927       radboud           5           4+5   \n",
       "2  6468063d0445cf082716fa830a507de2       radboud           0           0+0   \n",
       "3  b2545fbd121c537ccb04c90cef91631c       radboud           2           3+4   \n",
       "4  16e1c7937dc0a2394bf82f863dd1a25f    karolinska           0           0+0   \n",
       "\n",
       "   split  prim_gleason  secon_gleason  \n",
       "0      3             1              1  \n",
       "1      0             2              3  \n",
       "2      0             0              0  \n",
       "3      3             1              2  \n",
       "4      1             0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(LABELS).set_index('image_id')\n",
    "# susp = pd.read_csv('PANDA_Suspicious_Slides.csv')\n",
    "# #['marks', 'No Mask', 'Background only', 'No cancerous tissue but ISUP Grade > 0', 'tiss', 'blank']\n",
    "# to_drop = susp.query(\"reason in ['marks','Background only','tiss','blank']\")['image_id']\n",
    "# files = list(set(df.index)-set(to_drop))#good indices\n",
    "# print(\"All indices={0} | Bad indices={1} | Good indices used further={2}\".format(df.shape[0],len(to_drop),len(files)))\n",
    "# df = df.loc[files]\n",
    "# print(\"After filtering bad images:\",df.shape)\n",
    "files = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\n",
    "\n",
    "df = df.loc[files]\n",
    "print(\"After filtering bad images:\",df.shape)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "splits = list(splits.split(df,df.isup_grade))\n",
    "folds_splits = np.zeros(len(df)).astype(np.int)\n",
    "for i in range(nfolds): \n",
    "    folds_splits[splits[i][1]] = i\n",
    "df['split'] = folds_splits\n",
    "df['gleason_score']=df['gleason_score'].replace('negative','0+0')\n",
    "df[['prim_gleason','secon_gleason']] = df.gleason_score.str.split(\"+\",expand=True)\n",
    "df[['prim_gleason','secon_gleason']] = df[['prim_gleason','secon_gleason']].astype(np.int64)\n",
    "df['prim_gleason']=df['prim_gleason'].replace(3,1)\n",
    "df['prim_gleason']=df['prim_gleason'].replace(4,2)\n",
    "df['prim_gleason']=df['prim_gleason'].replace(5,3)\n",
    "df['secon_gleason']=df['secon_gleason'].replace(3,1)\n",
    "df['secon_gleason']=df['secon_gleason'].replace(4,2)\n",
    "df['secon_gleason']=df['secon_gleason'].replace(5,3)\n",
    "print(\"\\n>>>>>>>>>Before sampling<<<<<<<<<<<<<\",df.shape)\n",
    "for isup in [0,1,2,3,4,5]:\n",
    "    print(\"isup grade:\",isup,\"| n_instances:\",df.query('isup_grade=={0}'.format(isup)).shape[0],\"| corresponding gleason score:\",df[['isup_grade','gleason_score']].query('isup_grade=={0}'.format(isup))['gleason_score'].unique())\n",
    "    print(\"----\"*20)\n",
    "#df.drop([df[df['image_id']==\"b0a92a74cb53899311acc30b7405e101\"].index[0]],inplace=True)\n",
    "#b0a92a74cb53899311acc30b7405e101 is the only image id with gleason 4+3 mapping to isup=2\n",
    "df = pd.concat([df.query('isup_grade==0').iloc[:1200],df.query('isup_grade==1').iloc[:1200],df.query('isup_grade==2 or isup_grade==3 or isup_grade==4 or isup_grade==5')],axis=0)\n",
    "print(\"\\n>>>>>>>>>After Balancing data manually by selecting first 1200 from isup_grades 0 and 1<<<<<<<<<<<<<\",df.shape)\n",
    "for isup in [0,1,2,3,4,5]:\n",
    "    print(\"isup grade:\",isup,\"| n_instances:\",df.query('isup_grade=={0}'.format(isup)).shape[0],\"| corresponding gleason score:\",df[['isup_grade','gleason_score']].query('isup_grade=={0}'.format(isup))['gleason_score'].unique())\n",
    "    print(\"----\"*20)\n",
    "df = df.sample(n=5000,random_state=SEED).reset_index(drop=True)#shuffling\n",
    "print(\"\\n>>>>>>>>>After sampling<<<<<<<<<<\",df.shape)\n",
    "for isup in [0,1,2,3,4,5]:\n",
    "    print(\"isup grade:\",isup,\"| n_instances:\",df.query('isup_grade=={0}'.format(isup)).shape[0],\"| corresponding gleason score:\",df[['isup_grade','gleason_score']].query('isup_grade=={0}'.format(isup))['gleason_score'].unique())\n",
    "    print(\"----\"*20)\n",
    "df[['isup_grade','split']].hist(bins=50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f07f9dffdd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df['data_provider'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check [this kernel](https://www.kaggle.com/iafoss/panda-16x128x128-tiles) for image stats. Since I use zero padding and background corresponds to 255, I invert images as 255-img when load them. Therefore, the mean value is computed as '1 - val'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\n",
    "std = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n",
    "#mean: [0.96589806 0.9326964  0.95441414] , std: [0.30177967 0.4173849  0.33891267]for 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below (in the hidden cell) creates ImageItemList capable of loading multiple tiles of an image. It is specific for fast.ai, and pure Pytorch code would be much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def open_image(fn:PathOrStr, div:bool=True, convert_mode:str='RGB', cls:type=Image,after_open:Callable=None)->Image:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        x = PIL.Image.open(fn).convert(convert_mode)\n",
    "    if after_open: \n",
    "        x = after_open(x)\n",
    "    x = pil2tensor(x,np.float32)\n",
    "    if div: \n",
    "        x.div_(255)\n",
    "    return cls(1.0-x) #invert image for zero padding\n",
    "\n",
    "class MImage(ItemBase):\n",
    "    def __init__(self, imgs):\n",
    "        self.obj  = (imgs)\n",
    "        self.data = [(imgs[i].data - mean[...,None,None])/std[...,None,None] for i in range(len(imgs))]\n",
    "    \n",
    "    def apply_tfms(self, tfms,*args, **kwargs):\n",
    "        for i in range(len(self.obj)):\n",
    "            self.obj[i] = self.obj[i].apply_tfms(tfms, *args, **kwargs)\n",
    "            self.data[i] = (self.obj[i].data - mean[...,None,None])/std[...,None,None]\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self): \n",
    "        return f'{self.__class__.__name__} {img.shape for img in self.obj}'\n",
    "    \n",
    "    def to_one(self):\n",
    "        img = torch.stack(self.data,1)\n",
    "        img = img.view(3,-1,N,sz,sz).permute(0,1,3,2,4).contiguous().view(3,-1,sz*N)\n",
    "        return Image(1.0 - (mean[...,None,None]+img*std[...,None,None]))\n",
    "\n",
    "class MImageItemList(ImageList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def __len__(self)->int: return len(self.items) or 1 \n",
    "    \n",
    "    def get(self, i):\n",
    "        fn = Path(self.items[i])\n",
    "        fnames = [Path(str(fn)+'_'+str(i)+'.png')for i in range(N)]\n",
    "        imgs = [open_image(fname, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "               for fname in fnames]\n",
    "        return MImage(imgs)\n",
    "\n",
    "    def reconstruct(self, t):\n",
    "        return MImage([mean[...,None,None]+_t*std[...,None,None] for _t in t])\n",
    "    \n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(300,50), **kwargs):\n",
    "        rows = min(len(xs),8)\n",
    "        fig, axs = plt.subplots(rows,1,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            xs[i].to_one().show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "#collate function to combine multiple images into one tensor\n",
    "def MImage_collate(batch:ItemsList)->Tensor:\n",
    "    result = torch.utils.data.dataloader.default_collate(to_data(batch))\n",
    "    if isinstance(result[0],list):\n",
    "        result = [torch.stack(result[0],1),result[1]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 'Tesla T4',\n",
       " _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dc4034659aa2ae3585cdbe6febd3540b' in list(df['image_id']),torch.cuda.get_device_name(),torch.cuda.get_device_properties(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fold=0):\n",
    "    return (MImageItemList.from_df(df, path='.', folder=TRAIN, cols='image_id')\n",
    "      .split_by_idx(df.index[df.split == fold].tolist())\n",
    "      .label_from_df(cols=['isup_grade'])\n",
    "      .transform(get_transforms(flip_vert=True,max_rotate=15),size=sz,padding_mode='zeros')\n",
    "      .databunch(bs=bs,num_workers=4,device='cuda'))\n",
    "data = get_data(0)\n",
    "#data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128]) torch.Size([32, 3, 128, 128]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# i[1] contains labels, indicating isup grades\n",
    "# preds,y,losses = learn.get_preds(with_loss=True)\n",
    "# interp = ClassificationInterpretation(learn, preds, y, losses)\n",
    "for i in data.dl():\n",
    "    print(i[0][0].shape,i[0][7].shape,i[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below implements Concat Tile pooling idea. As a backbone I use [Semi-Weakly Supervised ImageNet pretrained ResNeXt50 model](https://github.com/facebookresearch/semi-supervised-ImageNet1K-models), which worked for me quite well in a number of previous competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNeSt,  \n",
    "employs Split-Attention block that enables attention across feature-map groups by stacking these Split-Attention blocks ResNet-style. Better results on 224 x 224.  \n",
    "m = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from squeeze import *\n",
    "# m = se_resnext101_32x4d(6,loss='softmax', pretrained=True)\n",
    "# len(list(nn.Sequential(*list(m.children())[:-2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n=6, pre=True):\n",
    "        super().__init__()\n",
    "        #m = se_resnext101_32x4d(n,loss='softmax', pretrained=True)\n",
    "        m = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),\n",
    "                                  Flatten(),\n",
    "                                  nn.Linear(2*nc,512),\n",
    "                                  Mish(),\n",
    "                                  nn.BatchNorm1d(512), \n",
    "                                  nn.Dropout(0.5),\n",
    "                                  nn.Linear(512,256),\n",
    "                                  Mish(),\n",
    "                                  nn.BatchNorm1d(256), \n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(256,n))\n",
    "        \n",
    "        \n",
    "    def forward(self, *x):\n",
    "        shape = x[0].shape\n",
    "        n = len(x)\n",
    "        x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data  = get_data(3)\n",
    "# model = Model()\n",
    "# gleason_loss = LabelSmoothingCrossEntropy()\n",
    "# learn = Learner(data,model,loss_func=gleason_loss, opt_func=Over9000, metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "# learn.loss_func=learn.loss_func.to('cuda')\n",
    "# learn.model=learn.model.to('cuda')\n",
    "# learn.clip_grad = 1.0\n",
    "# learn.split([learn.model.enc[0],learn.model.enc[1],learn.model.enc[2],learn.model.enc[3],learn.model.enc[4],learn.model.head])\n",
    "# learn.freeze()#first, train only the last layer(the heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()\n",
    "# plt.title(\"Loss Vs Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learn.fit_one_cycle(5, max_lr=1e-2,div_factor=100,pct_start=0.0,callbacks = [SaveModelCallback(learn,name='stage1',monitor='kappa_score')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('stage1')\n",
    "# learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learn.fit_one_cycle(5, max_lr=slice(1e-5,1e-3),div_factor=100,pct_start=0.0,callbacks = [SaveModelCallback(learn,name='stage2',monitor='kappa_score')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Fold- 0 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nizamphoenix/.cache/torch/hub/zhanghang1989_ResNeSt_master\n",
      "Downloading: \"https://s3.us-west-1.wasabisys.com/resnest/torch/resnest50-528c19ca.pth\" to /home/nizamphoenix/.cache/torch/hub/checkpoints/resnest50-528c19ca.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df258e3a605439784aa23a05bf6fd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=110273258.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.716441</td>\n",
       "      <td>1.740840</td>\n",
       "      <td>0.424213</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.609540</td>\n",
       "      <td>1.562849</td>\n",
       "      <td>0.546278</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.555106</td>\n",
       "      <td>1.585436</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.507672</td>\n",
       "      <td>1.546921</td>\n",
       "      <td>0.549565</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.491108</td>\n",
       "      <td>1.532131</td>\n",
       "      <td>0.552602</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.424213171005249.\n",
      "Better model found at epoch 1 with kappa_score value: 0.5462782979011536.\n",
      "Better model found at epoch 3 with kappa_score value: 0.5495650768280029.\n",
      "Better model found at epoch 4 with kappa_score value: 0.5526024103164673.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.489176</td>\n",
       "      <td>1.531855</td>\n",
       "      <td>0.546759</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.498204</td>\n",
       "      <td>1.532886</td>\n",
       "      <td>0.553048</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.479460</td>\n",
       "      <td>1.533432</td>\n",
       "      <td>0.545248</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.487870</td>\n",
       "      <td>1.524358</td>\n",
       "      <td>0.560799</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.482079</td>\n",
       "      <td>1.535971</td>\n",
       "      <td>0.537549</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.5467586517333984.\n",
      "Better model found at epoch 1 with kappa_score value: 0.5530480146408081.\n",
      "Better model found at epoch 3 with kappa_score value: 0.5607990026473999.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='40' class='' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [40/40 00:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Fold- 1 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nizamphoenix/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.715122</td>\n",
       "      <td>1.624592</td>\n",
       "      <td>0.528082</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.630028</td>\n",
       "      <td>1.591532</td>\n",
       "      <td>0.511524</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.552585</td>\n",
       "      <td>1.525147</td>\n",
       "      <td>0.573774</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.522873</td>\n",
       "      <td>1.539355</td>\n",
       "      <td>0.546979</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.499598</td>\n",
       "      <td>1.534495</td>\n",
       "      <td>0.558788</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.528082013130188.\n",
      "Better model found at epoch 2 with kappa_score value: 0.573773980140686.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.528646</td>\n",
       "      <td>1.531099</td>\n",
       "      <td>0.576496</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.518194</td>\n",
       "      <td>1.532747</td>\n",
       "      <td>0.564292</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.529488</td>\n",
       "      <td>1.532069</td>\n",
       "      <td>0.574970</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.513968</td>\n",
       "      <td>1.529929</td>\n",
       "      <td>0.568994</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.517781</td>\n",
       "      <td>1.525247</td>\n",
       "      <td>0.569513</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.5764960050582886.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='40' class='' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [40/40 00:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Fold- 2 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nizamphoenix/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.703293</td>\n",
       "      <td>1.714737</td>\n",
       "      <td>0.521575</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.628542</td>\n",
       "      <td>1.575683</td>\n",
       "      <td>0.569876</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.560730</td>\n",
       "      <td>1.544438</td>\n",
       "      <td>0.574122</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.529143</td>\n",
       "      <td>1.533996</td>\n",
       "      <td>0.587949</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.496002</td>\n",
       "      <td>1.526058</td>\n",
       "      <td>0.596610</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.5215752124786377.\n",
      "Better model found at epoch 1 with kappa_score value: 0.569875955581665.\n",
      "Better model found at epoch 2 with kappa_score value: 0.5741219520568848.\n",
      "Better model found at epoch 3 with kappa_score value: 0.5879493951797485.\n",
      "Better model found at epoch 4 with kappa_score value: 0.5966101288795471.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.483028</td>\n",
       "      <td>1.521877</td>\n",
       "      <td>0.601602</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.506802</td>\n",
       "      <td>1.523548</td>\n",
       "      <td>0.592051</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.489879</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0.600886</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.501159</td>\n",
       "      <td>1.529810</td>\n",
       "      <td>0.597359</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.497228</td>\n",
       "      <td>1.520819</td>\n",
       "      <td>0.601226</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.6016018390655518.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='39' class='' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [39/39 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Fold- 3 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nizamphoenix/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.704351</td>\n",
       "      <td>1.725681</td>\n",
       "      <td>0.476936</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.617252</td>\n",
       "      <td>1.596856</td>\n",
       "      <td>0.512582</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.561784</td>\n",
       "      <td>1.617761</td>\n",
       "      <td>0.498972</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.521649</td>\n",
       "      <td>1.577744</td>\n",
       "      <td>0.515909</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.495279</td>\n",
       "      <td>1.556941</td>\n",
       "      <td>0.555457</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.4769356846809387.\n",
      "Better model found at epoch 1 with kappa_score value: 0.5125824213027954.\n",
      "Better model found at epoch 3 with kappa_score value: 0.5159088373184204.\n",
      "Better model found at epoch 4 with kappa_score value: 0.5554567575454712.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.489959</td>\n",
       "      <td>1.562913</td>\n",
       "      <td>0.546602</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.479957</td>\n",
       "      <td>1.564473</td>\n",
       "      <td>0.549723</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.489479</td>\n",
       "      <td>1.559208</td>\n",
       "      <td>0.557296</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.479342</td>\n",
       "      <td>1.561334</td>\n",
       "      <td>0.555277</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.484606</td>\n",
       "      <td>1.557518</td>\n",
       "      <td>0.550951</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.5466022491455078.\n",
      "Better model found at epoch 1 with kappa_score value: 0.5497226119041443.\n",
      "Better model found at epoch 2 with kappa_score value: 0.5572963953018188.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='40' class='' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [40/40 00:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = 'ResNeSt50'\n",
    "pred,target = [],[]\n",
    "for fold in range(nfolds):#nfolds\n",
    "    print(\"-\"*40,\"Fold-\",fold,\"-\"*40)\n",
    "    data  = get_data(fold)\n",
    "    model = Model()\n",
    "    gleason_loss = LabelSmoothingCrossEntropy()\n",
    "    learn = Learner(data,model,loss_func=gleason_loss, opt_func=Over9000, metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "    learn.loss_func=learn.loss_func.to('cuda')\n",
    "    learn.model=learn.model.to('cuda')\n",
    "    learn.clip_grad = 1.0\n",
    "    learn.split([learn.model.enc[0],learn.model.enc[1],learn.model.enc[2],learn.model.enc[3],learn.model.enc[4],learn.model.head])\n",
    "    learn.freeze()#first, train only the last layer(the heads)\n",
    "    learn.fit_one_cycle(5, max_lr=1e-2, div_factor=100, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name='stage1_{0}'.format(fold),monitor='kappa_score')])\n",
    "    logger = CSVLogger(learn, f'log_{fname}_{fold}')\n",
    "    learn.load('stage1_{0}'.format(fold))\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(5, max_lr=slice(1e-6,1e-4), div_factor=100, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name='stage2_{0}'.format(fold),monitor='kappa_score')])\n",
    "    \n",
    "    torch.save(learn.model.state_dict(), f'{fname}_{fold}.pth')\n",
    "    \n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in progress_bar(enumerate(data.dl(DatasetType.Valid)),\n",
    "                                     total=len(data.dl(DatasetType.Valid))):\n",
    "            p = learn.model(*x)\n",
    "            pred.append(p.float().cpu())\n",
    "            target.append(y.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5738310178838769\n",
      "[[572  96  24  31 100  19]\n",
      " [267 192 157  71 156  14]\n",
      " [128 116 261 165 191  35]\n",
      " [ 60  36 105 229 255 106]\n",
      " [ 68  47  62 123 402 115]\n",
      " [ 53  12  50 104 222 356]]\n"
     ]
    }
   ],
   "source": [
    "p = torch.argmax(torch.cat(pred,dim=0),1)      \n",
    "t = torch.cat(target)\n",
    "print(cohen_kappa_score(t,p,weights='quadratic'))      \n",
    "print(confusion_matrix(t,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------------------------------------------------------------------------- End --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = torch.hub.load('facebookresearch/detr', model='detr_resnet50')\n",
    "# there are 8 blocks in resnext 50\n",
    "# print(list(m.children())[:-2][0],'\\n',list(m.children())[:-2][1],'\\n',list(m.children())[:-2][2],'\\n',list(m.children())[:-2][3])\n",
    "# for i in [4,5,6,7]:\n",
    "#     print(list(m.children())[:-2][i])\n",
    "#     print(\"-\"*100)#,list(m.children())[:-2][5],list(m.children())[:-2][6],list(m.children())[:-2][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isup_preds_targs(preds,target):\n",
    "    lookup_map = {(0,0):0,(1,1):1,(1,2):2,(2,1):3,(2,2):4,(3,1):4,(1,3):4,(2,3):5,(3,2):5,(3,3):5}\n",
    "    lookup_map2 = {(0,1):1,(0,2):1,(0,3):2,(1,0):1,(2,0):3,(3,0):4}#or all 0\n",
    "    prim_preds = preds[0].argmax(-1).view(-1,1)\n",
    "    sec_preds  = preds[1].argmax(-1).view(-1,1)\n",
    "    temp_preds = torch.cat([prim_preds,sec_preds],dim=1)\n",
    "    temp = []\n",
    "    count = 0\n",
    "    errors = 0\n",
    "    for i in np.array(temp_preds.cpu()):\n",
    "        count+=1\n",
    "        try:\n",
    "            temp.append(lookup_map[tuple(i)])\n",
    "        except KeyError:\n",
    "            #print(tuple(i),\" missins\")\n",
    "            errors+=1\n",
    "            temp.append(lookup_map2[tuple(i)])\n",
    "    print(\"count={0} | errors={1}\".format(count,errors),\" | correct=\",count-errors)\n",
    "    isup_preds = torch.tensor(temp,dtype=torch.long,device='cpu')\n",
    "    temp = []\n",
    "    for i in np.array(target.cpu()):\n",
    "        temp.append(lookup_map[tuple(i)])\n",
    "    isup_targs = torch.tensor(temp,dtype=torch.long,device='cpu')    \n",
    "    return isup_preds,isup_targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix(Callback):\n",
    "    \"Computes the confusion matrix.\"\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.n_classes = 0\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.cm = None\n",
    "\n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "        preds = last_output.argmax(-1).view(-1).cpu()\n",
    "        targs = last_target.cpu()\n",
    "        if self.n_classes == 0:\n",
    "            self.n_classes = last_output.shape[-1]\n",
    "        if self.cm is None: self.cm = torch.zeros((self.n_classes, self.n_classes), device=torch.device('cpu'))\n",
    "        cm_temp_numpy = self.cm.numpy()\n",
    "        np.add.at(cm_temp_numpy, (targs ,preds), 1)\n",
    "        self.cm = torch.from_numpy(cm_temp_numpy)\n",
    "\n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        self.metric = self.cm\n",
    "        \n",
    "@dataclass\n",
    "class KappaScore(ConfusionMatrix):\n",
    "    \"Computes the rate of agreement (Cohens Kappa).\"\n",
    "    weights:Optional[str]=None      # None, `linear`, or `quadratic`\n",
    "        \n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "#         print(\"Customised scoring function....\")\n",
    "#         print(last_output[0].shape,last_output[1].shape,last_target.shape)\n",
    "#         print(last_output)\n",
    "#         print(last_target)\n",
    "        preds,targs = get_isup_preds_targs(last_output,last_target)#convert gleasons-->isup for evaluatio\n",
    "\n",
    "        if self.n_classes == 0:\n",
    "            self.n_classes = 6 #n_classes in isup_grade\n",
    "        if self.cm is None: \n",
    "            #This executes only once\n",
    "            self.cm = torch.zeros((self.n_classes, self.n_classes), device=torch.device('cpu'))\n",
    "        cm_temp_numpy = self.cm.numpy()\n",
    "        np.add.at(cm_temp_numpy, (targs ,preds), 1)\n",
    "        self.cm = torch.from_numpy(cm_temp_numpy)\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        sum0 = self.cm.sum(dim=0)\n",
    "        sum1 = self.cm.sum(dim=1)\n",
    "        expected = torch.einsum('i,j->ij', (sum0, sum1)) / sum0.sum()\n",
    "        if self.weights is None:\n",
    "            w = torch.ones((self.n_classes, self.n_classes))\n",
    "            w[self.x, self.x] = 0\n",
    "        elif self.weights == \"linear\" or self.weights == \"quadratic\":\n",
    "            w = torch.zeros((self.n_classes, self.n_classes))\n",
    "            w += torch.arange(self.n_classes, dtype=torch.float)\n",
    "            w = torch.abs(w - torch.t(w)) if self.weights == \"linear\" else (w - torch.t(w)) ** 2\n",
    "        else: raise ValueError('Unknown weights. Expected None, \"linear\", or \"quadratic\".')\n",
    "        k = torch.sum(w * self.cm) / torch.sum(w * expected)\n",
    "        return add_metrics(last_metrics, 1-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnext(layers, pretrained, progress, **kwargs):\n",
    "    from torchvision.models.resnet import ResNet, Bottleneck\n",
    "    model = ResNet(Bottleneck, layers, **kwargs)\n",
    "    model.load_state_dict(torch.load('./resnext-50-ssl/semi_supervised_resnext50_32x4-ddb3e555.pth'))\n",
    "    return model\n",
    "\n",
    "\n",
    "class GleasonModel(nn.Module):\n",
    "    '''\n",
    "    Multi-task neural network trained on major(primary) and minor(secondary) gleason scores instead of\n",
    "    isup grade.\n",
    "    Backbones:-\n",
    "    1.resnext:'facebookresearch/semi-supervised-ImageNet1K-models',model='resnext50_32x4d_ssl'\n",
    "    2.resnest:'zhanghang1989/ResNeSt', model='resnest50'\n",
    "    3.seresnext: https://kaiyangzhou.github.io/deep-person-reid/pkg/\n",
    "    3.detr:\n",
    "    '''\n",
    "    def __init__(self, n=4):#n=4 since model is trained on gleason scores\n",
    "        super().__init__()\n",
    "        #m = torch.hub.load(github='facebookresearch/detr', model='detr_resnet50_dc5', pretrained=True)\n",
    "        m = se_resnext50_32x4d(4,loss='softmax', pretrained=True)\n",
    "        \n",
    "        #m = get_resnext([3, 4, 6, 3], pretrained=True, progress=False, groups=32,width_per_group=4)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),\n",
    "                                  Flatten(),\n",
    "#                                   nn.Linear(2*nc,512),\n",
    "#                                   Mish(),\n",
    "#                                   nn.BatchNorm1d(512), \n",
    "#                                   nn.Dropout(0.5),\n",
    "                                  nn.Linear(2*nc,512),\n",
    "                                  Mish(),\n",
    "                                  nn.BatchNorm1d(512), \n",
    "                                  nn.Dropout(0.3))\n",
    "        self.prim =  nn.Linear(512,n)\n",
    "        self.sec  =  nn.Linear(512,n)\n",
    "      \n",
    "        \n",
    "        \n",
    "    def forward(self, *x):\n",
    "        shape = x[0].shape\n",
    "        n = len(x)\n",
    "        x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        prim_gleason = self.prim(x)\n",
    "        sec_gleason  = self.sec(x)\n",
    "        preds = [prim_gleason,sec_gleason]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskGleasonLoss(nn.Module):\n",
    "    def __init__(self, task_num):\n",
    "        super(MultiTaskGleasonLoss, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        self.log_vars = nn.Parameter(torch.zeros((task_num)))\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "#         print(\"type(preds):\",type(preds),\"| len(preds):\",len(preds),\"| preds[0].shape:\",preds[0].shape,\"| preds[1].shape:\",preds[1].shape)\n",
    "#         print(\"type(targets):\",type(targets),\"| targets[:,0].shape:\",targets[:,0].shape,\"| targets[:,1].shape:\",targets[:,1].shape)\n",
    "        crossEntropy = nn.CrossEntropyLoss()\n",
    "#         print(\"Before typecasting: \",preds[0].device,preds[0].dtype,targets[:,0].device,targets[:,0].dtype)\n",
    "        prim_preds  = preds[0]\n",
    "        prim_target = targets[:,0].long()\n",
    "        loss1 = crossEntropy(prim_preds,prim_target)\n",
    "#         print(\"After typecasting: \",prim_preds.device,prim_preds.dtype,prim_target.device,prim_target.dtype)\n",
    "        precision1 = torch.exp(-self.log_vars[0])\n",
    "        loss1 = precision1*loss1 + self.log_vars[0]   \n",
    "        \n",
    "        sec_preds  = preds[1]\n",
    "        sec_target = targets[:,1].long()\n",
    "        loss2 = crossEntropy(sec_preds,sec_target)\n",
    "        precision2 = torch.exp(-self.log_vars[1])\n",
    "        loss2 = precision2*loss2 + self.log_vars[1]   \n",
    "        \n",
    "        return loss1+loss2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = get_data(0)\n",
    "model = GleasonModel()\n",
    "gleason_loss = MultiTaskGleasonLoss(2)\n",
    "learn = Learner(data,model,loss_func=gleason_loss, opt_func=Over9000, metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "learn.loss_func=learn.loss_func.to('cuda')\n",
    "learn.model=learn.model.to('cuda')\n",
    "learn.clip_grad = 1.0\n",
    "learn.split([learn.model.head,nn.ModuleList([learn.model.prim,learn.model.sec])])\n",
    "learn.freeze()#first, train only the last layer(the heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()\n",
    "plt.title(\"Loss Vs Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=1e-1, div_factor=25, pct_start=0.0, callbacks = [SaveModelCallback(learn,name='freezed_trained',monitor='kappa_score')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage2')\n",
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()\n",
    "plt.title(\"Loss Vs Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, max_lr=slice(1e-5,1e-2), div_factor=25, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name='stage2',monitor='kappa_score')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'RNXT50'\n",
    "pred,target = [],[]\n",
    "for fold in range(nfolds):#nfolds\n",
    "    print(\"-\"*40,\"Fold-\",fold,\"-\"*40)\n",
    "    data  = get_data(fold)\n",
    "    model = GleasonModel()\n",
    "    gleason_loss = MultiTaskGleasonLoss(2)\n",
    "    learn = Learner(data,model,loss_func=gleason_loss, opt_func=Over9000, metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "    learn.loss_func=learn.loss_func.to('cuda')\n",
    "    learn.model=learn.model.to('cuda')\n",
    "    learn.clip_grad = 1.0\n",
    "    learn.split([learn.model.enc[0:6],learn.model.enc[6:8],learn.model.head,nn.ModuleList([learn.model.prim,learn.model.sec])])\n",
    "    learn.freeze()\n",
    "    learn.fit_one_cycle(2, max_lr=1e-1, div_factor=100, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name='stage1_{0}'.format(fold),monitor='kappa_score')])\n",
    "    logger = CSVLogger(learn, f'log_{fname}_{fold}')\n",
    "    learn.load('stage1_{0}'.format(fold))\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(3, max_lr=slice(1e-5,1e-3), div_factor=100, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name='stage2_{0}'.format(fold),monitor='kappa_score')])\n",
    "    \n",
    "    torch.save(learn.model.state_dict(), f'{fname}_{fold}.pth')\n",
    "    \n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in progress_bar(enumerate(data.dl(DatasetType.Valid)),total=len(data.dl(DatasetType.Valid))):\n",
    "            #print(len(x),x[0].shape)\n",
    "            p = learn.model(*x) \n",
    "            preds,targs = get_isup_preds_targs(p,y)\n",
    "            pred.append(preds)\n",
    "            target.append(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "p = torch.argmax(torch.cat(pred,dim=0),1)      \n",
    "t = torch.cat(target)\n",
    "print(cohen_kappa_score(t,p,weights='quadratic'))\n",
    "print(confusion_matrix(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(torch.cat(target),torch.cat(pred,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(torch.cat(target),torch.cat(pred,dim=0),weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "!rm -r 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torchviz\n",
    "# import torch\n",
    "# from torchviz import make_dot\n",
    "# model = Model()\n",
    "# x = torch.randn(2, 3, 128, 128).requires_grad_(True)\n",
    "# y = model(x)\n",
    "# make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)])).render(\"attached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "#         super().__init__()\n",
    "#         #m = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "#         self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "#         nc = list(m.children())[-1].in_features\n",
    "#         self.head = nn.Sequential(AdaptiveConcatPool2d(),\n",
    "#                                   Flatten(),\n",
    "#                                   nn.Linear(2*nc,128),\n",
    "#                                   Mish(),\n",
    "#                                   nn.BatchNorm1d(128), \n",
    "#                                   nn.Dropout(0.5),\n",
    "#                                   nn.Linear(128,n))\n",
    "        \n",
    "        \n",
    "#     def forward(self, *x):\n",
    "#         shape = x[0].shape\n",
    "#         n = len(x)\n",
    "#         x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "#         #x: bs*N x 3 x 128 x 128\n",
    "#         x = self.enc(x)\n",
    "#         #x: bs*N x C x 4 x 4\n",
    "#         shape = x.shape\n",
    "#         #concatenate the output for tiles into a single map\n",
    "#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n",
    "#         #x: bs x C x N*4 x 4\n",
    "#         x = self.head(x)\n",
    "#         #x: bs x n\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #UNDERSAMPLING\n",
    "# import seaborn as sns\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=SEED)\n",
    "# X_resampled, y_resampled = rus.fit_resample(df[['image_id', 'data_provider','split']].iloc[:8000], df['isup_grade'].iloc[:8000])\n",
    "# df = pd.concat([pd.DataFrame(X_resampled,columns=['image_id', 'data_provider','split']),pd.DataFrame(y_resampled,columns=['isup_grade'])],axis=1)\n",
    "# df = df.sample(frac=1,random_state=SEED).reset_index(drop=True)\n",
    "# sns.countplot(df['isup_grade'])\n",
    "# df.head()\n",
    "# df = df.groupby(['split'], group_keys=False).apply(lambda x: x.sample(min(len(x), 1000),random_state=SEED))\n",
    "# df[['isup_grade','split']].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1=torch.tensor([[-8.8875e+01,  3.9062e+01, -6.1406e+00, -6.6625e+01],\n",
    "#         [-3.3781e+01,  1.4578e+01, -8.6133e-01, -2.5047e+01],\n",
    "#         [-2.9297e+00,  1.2412e+00,  9.8584e-01, -2.6113e+00],\n",
    "#         [-1.6992e-01,  3.9355e-01,  4.3701e-01, -1.1953e+00],\n",
    "#         [-5.7910e-01,  6.8457e-01,  4.6216e-01, -1.4893e+00],\n",
    "#         [-1.7639e-01,  4.2603e-01,  3.8843e-01, -1.2490e+00],\n",
    "#         [-1.6297e+01,  7.1523e+00,  4.3018e-01, -1.2164e+01],\n",
    "#         [-1.6333e-01,  4.3164e-01,  3.7207e-01, -1.2646e+00],\n",
    "#         [-4.8309e-02,  4.4946e-01,  3.0298e-01, -1.1963e+00],\n",
    "#         [-3.6844e+01,  1.6312e+01, -2.1621e+00, -2.7594e+01],\n",
    "#         [        0,         1,         0,         0],\n",
    "#         [-7.6721e-02,  4.3408e-01,  3.4644e-01, -1.1943e+00],\n",
    "#         [-8.0875e+01,  3.5188e+01, -3.9707e+00, -5.9656e+01],\n",
    "#         [-6.1625e+01,  2.7312e+01, -3.2949e+00, -4.6594e+01],\n",
    "#         [-3.5906e+01,  1.5633e+01, -9.3945e-01, -2.6281e+01],\n",
    "#         [-2.1641e+01,  9.4062e+00,  6.9385e-01, -1.5695e+01],\n",
    "#         [-2.8781e+01,  1.2414e+01,  4.8706e-01, -2.0859e+01],\n",
    "#         [-3.0266e+01,  1.3586e+01, -1.4209e+00, -2.2922e+01],\n",
    "#         [        0,         1,         0,         0],\n",
    "#         [-3.6531e+01,  1.6172e+01, -1.5479e+00, -2.7625e+01],\n",
    "#         [-6.9580e-02,  4.5190e-01,  3.1958e-01, -1.2119e+00],\n",
    "#         [-6.0181e-02,  4.5117e-01,  3.1421e-01, -1.2178e+00],\n",
    "#         [-2.8711e-01,  3.8086e-01,  4.9854e-01, -1.2412e+00],\n",
    "#         [-4.4373e-02,  4.3896e-01,  3.1714e-01, -1.1748e+00],\n",
    "#         [-6.0028e-02,  4.4263e-01,  3.2349e-01, -1.1914e+00],\n",
    "#         [-9.6741e-02,  4.4019e-01,  3.5449e-01, -1.2178e+00],\n",
    "#         [-3.0762e+00,  1.5293e+00,  6.8506e-01, -2.8242e+00],\n",
    "#         [-5.3345e-02,  4.5386e-01,  3.0737e-01, -1.2119e+00],\n",
    "#         [-1.2711e+01,  5.7656e+00,  3.3203e-01, -9.6797e+00],\n",
    "#         [-6.6406e-02,  4.4727e-01,  3.2471e-01, -1.1963e+00],\n",
    "#         [-4.9042e-02,  4.3872e-01,  3.0420e-01, -1.1709e+00],\n",
    "#         [-1.6641e+00,  1.1172e+00,  5.8203e-01, -2.0605e+00]])\n",
    "# t2=torch.tensor([[-5.9812e+01,  1.6828e+01, -1.5188e+01,  4.7781e+01],\n",
    "#         [-2.2938e+01,  7.0039e+00, -5.7188e+00,  1.8125e+01],\n",
    "#         [-2.1074e+00,  8.9258e-01, -4.4336e-01,  1.7598e+00],\n",
    "#         [-4.0796e-01,  5.6299e-01, -8.6121e-02, -2.2437e-01],\n",
    "#         [-5.1025e-01,  8.9648e-01, -3.6938e-01, -2.2949e-02],\n",
    "#         [-4.5142e-01,  6.2695e-01, -2.0935e-01, -1.9116e-01],\n",
    "#         [-1.1297e+01,  3.5859e+00, -2.5879e+00,  8.7109e+00],\n",
    "#         [-4.3408e-01,  6.1182e-01, -1.8848e-01, -2.2412e-01],\n",
    "#         [-2.7954e-01,  5.9863e-01, -2.1533e-01, -3.5278e-01],\n",
    "#         [-2.4562e+01,  7.7227e+00, -7.1094e+00,  2.0703e+01],\n",
    "#         [        0,         1,         0,         0],\n",
    "#         [-3.1030e-01,  5.6934e-01, -1.3806e-01, -3.4082e-01],\n",
    "#         [-5.5281e+01,  1.5883e+01, -1.3398e+01,  4.2781e+01],\n",
    "#         [-4.1875e+01,  1.1969e+01, -1.0406e+01,  3.2938e+01],\n",
    "#         [-2.4562e+01,  7.4766e+00, -6.0117e+00,  1.9375e+01],\n",
    "#         [-1.5336e+01,  5.4688e+00, -4.2070e+00,  1.1961e+01],\n",
    "#         [-2.0141e+01,  6.2305e+00, -4.4219e+00,  1.5086e+01],\n",
    "#         [-2.0578e+01,  6.3203e+00, -5.8203e+00,  1.7156e+01],\n",
    "#         [        0,         1,         0,         0],\n",
    "#         [-2.4766e+01,  7.2578e+00, -6.2344e+00,  1.9750e+01],\n",
    "#         [-3.0591e-01,  6.0107e-01, -2.0142e-01, -3.3472e-01],\n",
    "#         [-2.9712e-01,  5.8789e-01, -1.8433e-01, -3.5400e-01],\n",
    "#         [-5.7617e-01,  5.8154e-01, -1.0052e-01, -8.4595e-02],\n",
    "#         [-2.5415e-01,  5.9082e-01, -1.9971e-01, -3.5474e-01],\n",
    "#         [-2.8394e-01,  6.0303e-01, -2.0618e-01, -3.4229e-01],\n",
    "#         [-3.3081e-01,  5.8594e-01, -1.5564e-01, -3.2251e-01],\n",
    "#         [-2.0703e+00,  9.4531e-01, -6.0254e-01,  1.8076e+00],\n",
    "#         [-2.9077e-01,  5.9424e-01, -1.9482e-01, -3.5474e-01],\n",
    "#         [-8.9766e+00,  2.7832e+00, -2.2129e+00,  7.0469e+00],\n",
    "#         [-2.8809e-01,  6.1279e-01, -2.1301e-01, -3.4375e-01],\n",
    "#         [-2.7637e-01,  6.0547e-01, -2.3462e-01, -3.2910e-01],\n",
    "#         [-1.1592e+00,  1.0586e+00, -5.2344e-01,  7.5098e-01]])\n",
    "# preds = [t1,t2]\n",
    "# target = torch.tensor([[1., 2.],\n",
    "#         [0., 0.],\n",
    "#         [2., 3.],\n",
    "#         [3., 3.],\n",
    "#         [0., 0.],\n",
    "#         [2., 1.],\n",
    "#         [0., 0.],\n",
    "#         [2., 2.],\n",
    "#         [2., 3.],\n",
    "#         [1., 1.],\n",
    "#         [2., 3.],\n",
    "#         [0., 0.],\n",
    "#         [2., 1.],\n",
    "#         [1., 2.],\n",
    "#         [1., 1.],\n",
    "#         [1., 2.],\n",
    "#         [2., 2.],\n",
    "#         [0., 0.],\n",
    "#         [2., 2.],\n",
    "#         [2., 3.],\n",
    "#         [2., 2.],\n",
    "#         [0., 0.],\n",
    "#         [3., 3.],\n",
    "#         [1., 2.],\n",
    "#         [2., 1.],\n",
    "#         [3., 3.],\n",
    "#         [2., 3.],\n",
    "#         [0., 0.],\n",
    "#         [2., 2.],\n",
    "#         [3., 2.],\n",
    "#         [2., 2.],\n",
    "#         [0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks for MultiTask:  \n",
    "https://github.com/hosseinshn/Basic-Multi-task-Learning/blob/master/MTL-Pytorch.ipynb  \n",
    "https://github.com/sugi-chan/pytorch_multitask/blob/master/pytorch%20multi-task-Copy2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
