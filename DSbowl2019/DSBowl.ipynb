{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import zipfile#external library--------------------REMOVE\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pylab as plt\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from typing import Any\n",
    "from numba import jit\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from itertools import product\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import random\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('/home/nizamphoenix/data-science-bowl-2019.zip') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(zf.open('train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping training ids that did not take assesment\n",
    "keep_id = train[train.type == \"Assessment\"][['installation_id']].drop_duplicates()\n",
    "train = pd.merge(train, keep_id, on=\"installation_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape,keep_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1 = sns.countplot(y=\"type\", data=train, color=\"blue\", order = train.type.value_counts().index)\n",
    "plt.title(\"number of events by type\")\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2 = sns.countplot(y=\"world\", data=train, color=\"blue\", order = train.world.value_counts().index)\n",
    "plt.title(\"number of events by world\")\n",
    "\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(zf.open('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "print(f'The date range in train is: {train.timestamp.dt.date.min()} to {train.timestamp.dt.date.max()}')\n",
    "print(f'The date range in test is: {test.timestamp.dt.date.min()} to {test.timestamp.dt.date.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(zf.open('train_labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update()\n",
    "plt.figure()\n",
    "sns.countplot(y=\"title\", data=train_labels, color=\"blue\", order = train_labels.title.value_counts().index)\n",
    "plt.title(\"Counts of titles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update()\n",
    "se = train_labels.groupby(['title', 'accuracy_group'])['accuracy_group'].count().unstack('title')\n",
    "se.plot.bar(stacked=True,rot=0,figsize=(15,10))\n",
    "plt.title(\"Counts of accuracy group\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[train_labels.installation_id == \"0006a69f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train.installation_id == \"0006a69f\") & (train.type == \"Assessment\") & ((train.event_code==4100)|(train.event_code==4110))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Things don't add up...12 incorrect and 5 correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train.installation_id == \"0006a69f\") & ((train.type == \"Assessment\") & (train.title == 'Bird Measurer (Assessment)') & (train.event_code == 4110) |\n",
    "                                               (train.type == \"Assessment\") & (train.title != 'Bird Measurer (Assessment)') & (train.event_code == 4100))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now, we have 4 correct and 12 incorrect, which is in agreement with train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering train.csv again!!!!\n",
    "train = train[train.installation_id.isin(train_labels.installation_id.unique())]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_session is the only unique identifier in train_labels .\n",
    "print(f'Shape of train_labels: {train_labels.shape}')\n",
    "print(f'Number of unique game_sessions in train_labels: {train_labels.game_session.nunique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[(train_labels['num_correct']==0)&(train_labels['num_incorrect']>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating features for a given **game_sessions** since its unique in train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credits: Andrew Lukyanenko\n",
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credits: Massoud Hosseinali\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "                    \n",
    "            \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments\n",
    "\n",
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit: Andrew Lukyanenko\n",
    "def preprocess(reduce_train, reduce_test):\n",
    "    for df in [reduce_train, reduce_test]:\n",
    "        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n",
    "        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n",
    "        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "        \n",
    "        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n",
    "                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n",
    "                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n",
    "        \n",
    "        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n",
    "        \n",
    "    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "    features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n",
    "   \n",
    "    return reduce_train, reduce_test, features\n",
    "# call feature engineering function\n",
    "reduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train=pd.read_csv('reduce_train.csv')\n",
    "reduce_test=pd.read_csv('reduce_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columms_not_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detour: Exploring Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def exponential_cov(x, y, params):\n",
    "    return params[0] * np.exp( -0.5 * params[1] * np.subtract.outer(x, y)**2)\n",
    "\n",
    "def conditional(x_new, x, y, params):\n",
    "    B = exponential_cov(x_new, x, params)\n",
    "    C = exponential_cov(x, x, params)\n",
    "    A = exponential_cov(x_new, x_new, params)\n",
    "    mu = np.linalg.inv(C).dot(B.T).T.dot(y)\n",
    "    sigma = A - B.dot(np.linalg.inv(C).dot(B.T))\n",
    "    return(mu.squeeze(), sigma.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pylab as plt\n",
    "'''\n",
    "We will start with a Gaussian process prior with hyperparameters theta_0=1, theta_1=10. \n",
    "We will also assume a zero function as the mean, \n",
    "so we can plot a band that represents one standard deviation from the mean.\n",
    "'''\n",
    "theta = [1, 10]#intial hyperparameters\n",
    "sigma_0 = exponential_cov(0, 0, theta)\n",
    "xpts = np.arange(-3, 3, step=0.01)\n",
    "plt.errorbar(xpts, np.zeros(len(xpts)), yerr=sigma_0, capsize=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.]\n",
    "y = [np.random.normal(scale=sigma_0)]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Updating our confidence band, given the point that we just sampled, \n",
    "using the covariance function to generate new point-wise intervals, conditional on the values x,y.\n",
    "'''\n",
    "sigma_1 = exponential_cov(x, x, theta)\n",
    " \n",
    "def predict(x, data, kernel, params, sigma, t):\n",
    "    k = [kernel(x, y, params) for y in data]\n",
    "    Sinv = np.linalg.inv(sigma)\n",
    "    y_pred = np.dot(k, Sinv).dot(t)\n",
    "    sigma_new = kernel(x, x, params) - np.dot(k, Sinv).dot(k)\n",
    "    return y_pred, sigma_new\n",
    " \n",
    "x_pred = np.linspace(-3, 3, 1000)\n",
    "predictions = [predict(i, x, exponential_cov, theta, sigma_1, y) for i in x_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, sigmas = np.transpose(predictions)\n",
    "plt.errorbar(x_pred, y_pred, yerr=sigmas, capsize=0)\n",
    "plt.plot(x, y, \"ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "So conditional on this point, and the covariance structure we have specified,\n",
    "we are constraining the probable locations of additional points.\n",
    "'''\n",
    "#Thus sampling another point\n",
    "xnew = -0.7\n",
    "m, s = conditional([xnew], x, y, theta)\n",
    "y2 = np.random.normal(m, s)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append(xnew)\n",
    "y.append(y2)\n",
    " \n",
    "sigma_2 = exponential_cov(x, x, theta)\n",
    "predictions = [predict(i, x, exponential_cov, theta, sigma_2, y) for i in x_pred]\n",
    "y_pred, sigmas = np.transpose(predictions)\n",
    "plt.errorbar(x_pred, y_pred, yerr=sigmas, capsize=0)\n",
    "plt.plot(x, y, \"ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instead of sampling one at a time, doing it all at once\n",
    "'''\n",
    "x_more = [-2.1, -1.5, 0.3, 1.8, 2.5]\n",
    "mu, s = conditional(x_more, x, y, theta)\n",
    "y_more = np.random.multivariate_normal(mu, s)\n",
    "\n",
    "x += x_more\n",
    "y += y_more.tolist()\n",
    " \n",
    "sigma_new = exponential_cov(x, x, theta)\n",
    "predictions = [predict(i, x, exponential_cov, theta, sigma_new, y) for i in x_pred]\n",
    " \n",
    "y_pred, sigmas = np.transpose(predictions)\n",
    "plt.errorbar(x_pred, y_pred, yerr=sigmas, capsize=0)\n",
    "plt.plot(x, y, \"ro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as the density of points becomes high, it results as a sample from the prior GP.  \n",
    "From -3 to -2 it can take any value from -1 to 1.  \n",
    "From -2 to -1 it can take any vale from -0.2 to 0.2.  \n",
    "The GP is a prior over the thickness of bands(confidence bands) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example:1D data\n",
    "X = np.random.uniform(-3.,3.,(20,1))\n",
    "noise = np.random.randn(20,1)*0.05\n",
    "Y = np.sin(X) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covariance function\n",
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)#input_dim=1 since 1D X\n",
    "#modelling\n",
    "m = GPy.models.GPRegression(X,Y,kernel)\n",
    "from IPython.display import display\n",
    "display(m)\n",
    "model_plot = m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **default values of the kernel parameters** may not be optimal for the current data (for example, the confidence intervals seems too wide on the previous figure). A common approach is to find the values of the parameters that maximize the likelihood of the data.  \n",
    "It as easy as calling **m.optimize** in GPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize(messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize_restarts(num_restarts = 10)#A kind of Grid search for finding optimal parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that 'm' has optimal hyperparameters, we plot it again!\n",
    "display(m)\n",
    "m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-D inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = -3.\n",
    "upper_limit = 3.\n",
    "num_input_samples = 50\n",
    "input_dim = 2\n",
    "# sample inputs and outputs\n",
    "X = np.random.uniform(lower_limit,upper_limit,(num_input_samples,input_dim))\n",
    "noise = np.random.randn(50,1)*0.05\n",
    "Y = np.sin(X[:,0:1]) * np.sin(X[:,1:2]) + noise\n",
    "X.shape,Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(8)*0.05\n",
    "X = np.array([[-1,1],[-2,2],[-3,3],[-4,4],[-5,5],[-6,6],[-7,7],[-8,8]])\n",
    "Y = np.array([[1,4,9,16,25,36,49,64]]) + noise\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSBowl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 901)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train = pd.read_csv('reduce_train.csv')\n",
    "reduce_test  = pd.read_csv('reduce_test.csv')\n",
    "reduce_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installation_id  also included to be dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = reduce_train['accuracy_group']\n",
    "cols_to_drop = []\n",
    "for i in (reduce_train.columns):\n",
    "    if type(i) is str and (not i.istitle()) and len(i)==8:\n",
    "        cols_to_drop.append(i)\n",
    "for col in reduce_train.columns:\n",
    "    try:\n",
    "        reduce_train[col] = reduce_train[col].astype('float64')\n",
    "    except:\n",
    "        print(col,\" also included to be dropped\")\n",
    "        cols_to_drop.append(col)\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 516), (17690, 1), (1000, 516))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reduce_train.drop(columns=cols_to_drop,axis=1)\n",
    "newX=reduce_test.drop(columns=cols_to_drop,axis=1)\n",
    "Y = Y.values.reshape(-1,1)\n",
    "X.shape,Y.shape,newX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                            0.0\n",
       "Clip                                  0.0\n",
       "Activity                              0.0\n",
       "Assessment                            0.0\n",
       "Game                                  0.0\n",
       "                                     ... \n",
       "installation_session_count            0.0\n",
       "installation_duration_mean            0.0\n",
       "installation_title_nunique            0.0\n",
       "sum_event_code_count                  0.0\n",
       "installation_event_code_count_mean    0.0\n",
       "Length: 516, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:8845].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[8845:17690].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbb670991cc45b4a5e55138b697b57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntProgress(value=0, max=1000), HTML(value=''))), Box(children=(HTML(value=''),)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mVerboseOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython_notebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mipython_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_after_finish\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_after_finish\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_fp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/optimization/optimization.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, x_init, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/optimization/optimization.py\u001b[0m in \u001b[0;36mopt\u001b[0;34m(self, x_init, f_fp, f, fp)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mopt_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/model.py\u001b[0m in \u001b[0;36m_objective_grads\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mobj_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_function_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/parameterized.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/core/parameter_core.py\u001b[0m in \u001b[0;36moptimizer_array\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_copy_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/core/updateable.py\u001b[0m in \u001b[0;36mtrigger_update\u001b[0;34m(self, trigger_parent)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/core/parameter_core.py\u001b[0m in \u001b[0;36m_trigger_params_changed\u001b[0;34m(self, trigger_parent)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_parent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fixed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrigger_parent\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/core/observable.py\u001b[0m in \u001b[0;36mnotify_observers\u001b[0;34m(self, which, min_priority)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_priority\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mcallble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/core/observable.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_priority\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mcallble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/core/parameter_core.py\u001b[0m in \u001b[0;36m_parameters_changed_notification\u001b[0;34m(self, me, which)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_copy_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# tells the optimizer array to update on next request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pass_through_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPy/core/gp.py\u001b[0m in \u001b[0;36mparameters_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_marginal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dthetaL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, kern, X, likelihood, Y, mean_function, Y_metadata, K, variance, Z_tilde)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdL_dK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPy/util/linalg.py\u001b[0m in \u001b[0;36mtdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtdot_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPy/util/linalg.py\u001b[0m in \u001b[0;36mtdot_blas\u001b[0;34m(mat, out)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.33 GiB for an array with shape (17690, 17690) and data type float64",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPy/core/gp.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_optimization_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_after_finish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyboardInterrupt caught, calling on_optimization_end() to round things up\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mVerboseOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython_notebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mipython_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_after_finish\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_after_finish\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_fp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/optimization/verbose_optimization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_observer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_notebook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/paramz/optimization/verbose_optimization.py\u001b[0m in \u001b[0;36mprint_out\u001b[0;34m(self, seconds)\u001b[0m\n\u001b[1;32m    146\u001b[0m                           ['||gradient||',\n\u001b[1;32m    147\u001b[0m                               \"{: >+12.3E}\".format(float(self.current_gradient))],\n\u001b[0;32m--> 148\u001b[0;31m                           \u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:s}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                           ]\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m#message = \"Lik:{:5.3E} Grad:{:5.3E} Lik:{:5.3E} Len:{!s}\".format(float(m.log_likelihood()), np.einsum('i,i->', grads, grads), float(m.likelihood.variance), \" \".join([\"{:3.2E}\".format(l) for l in m.kern.lengthscale.values]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define kernel\n",
    "ker = GPy.kern.RBF(X.shape[1])\n",
    "\n",
    "# create simple GP model\n",
    "m = GPy.models.GPRegression(X,Y,ker)\n",
    "\n",
    "# # optimize and plot\n",
    "m.optimize(messages=True,max_f_eval = 1000)\n",
    "display(m)\n",
    "m.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train['installation_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = np.asarray(newX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(newX)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df: pd.DataFrame, field_name: str,\n",
    "                 prefix: str = None, drop: bool = True, time: bool = True, date: bool = True):\n",
    "    \"\"\"\n",
    "    Helper function that adds columns relevant to a date in the column `field_name` of `df`.\n",
    "    from fastai: https://github.com/fastai/fastai/blob/master/fastai/tabular/transform.py#L55\n",
    "    \"\"\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Is_month_end', 'Is_month_start']\n",
    "    if date:\n",
    "        attr.append('Date')\n",
    "    if time:\n",
    "        attr = attr + ['Hour', 'Minute']\n",
    "    for n in attr:\n",
    "        df[prefix + n] = getattr(field.dt, n.lower())\n",
    "    if drop:\n",
    "        df.drop(field_name, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def ifnone(a: Any, b: Any) -> Any:\n",
    "    \"\"\"`a` if `a` is not None, otherwise `b`.\n",
    "    from fastai: https://github.com/fastai/fastai/blob/master/fastai/core.py#L92\"\"\"\n",
    "    return b if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#from bayes_opt import BayesianOptimization\n",
    "import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from typing import Any\n",
    "from itertools import product\n",
    "pd.set_option('max_rows', 500)\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import BaseEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "@jit\n",
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n",
    "\n",
    "\n",
    "def eval_qwk_lgb(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    y_pred[y_pred <= 1.12232214] = 0\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.12232214, y_pred <= 1.73925866))] = 1\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.73925866, y_pred <= 2.22506454))] = 2\n",
    "    y_pred[y_pred > 2.22506454] = 3\n",
    "\n",
    "    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "class LGBWrapper_regr(object):\n",
    "    \"\"\"\n",
    "    A wrapper for lightgbm model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = lgb.LGBMRegressor()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "        if params['objective'] == 'regression':\n",
    "            eval_metric = eval_qwk_lgb_regr\n",
    "        else:\n",
    "            eval_metric = 'auc'\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "            eval_names.append('valid')\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "            eval_names.append('holdout')\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = 'auto'\n",
    "        else:\n",
    "            categorical_columns = 'auto'\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_metric,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test, num_iteration=self.model.best_iteration_)\n",
    "\n",
    "    \n",
    "def eval_qwk_xgb(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for xgb.\n",
    "    \"\"\"\n",
    "    # print('y_true', y_true)\n",
    "    # print('y_pred', y_pred)\n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    return 'cappa', -qwk(y_true, y_pred)\n",
    "\n",
    "\n",
    "class LGBWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for lightgbm model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = lgb.LGBMClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "            eval_names.append('valid')\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "            eval_names.append('holdout')\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = 'auto'\n",
    "        else:\n",
    "            categorical_columns = 'auto'\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_qwk_lgb,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if self.model.objective == 'binary':\n",
    "            return self.model.predict_proba(X_test, num_iteration=self.model.best_iteration_)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, num_iteration=self.model.best_iteration_)\n",
    "\n",
    "\n",
    "class CatWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for catboost model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = cat.CatBoostClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        self.model = self.model.set_params(**{k: v for k, v in params.items() if k != 'cat_cols'})\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = None\n",
    "        else:\n",
    "            categorical_columns = None\n",
    "        \n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       cat_features=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if 'MultiClass' not in self.model.get_param('loss_function'):\n",
    "            return self.model.predict_proba(X_test, ntree_end=self.model.best_iteration_)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, ntree_end=self.model.best_iteration_)\n",
    "\n",
    "\n",
    "class XGBWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for xgboost model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_metric=eval_qwk_xgb,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'])\n",
    "\n",
    "        scores = self.model.evals_result()\n",
    "        self.best_score_ = {k: {m: m_v[-1] for m, m_v in v.items()} for k, v in scores.items()}\n",
    "        self.best_score_ = {k: {m: n if m != 'cappa' else -n for m, n in v.items()} for k, v in self.best_score_.items()}\n",
    "\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if self.model.objective == 'binary':\n",
    "            return self.model.predict_proba(X_test, ntree_limit=self.model.best_iteration)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, ntree_limit=self.model.best_iteration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MainTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, convert_cyclical: bool = False, create_interactions: bool = False, n_interactions: int = 20):\n",
    "        \"\"\"\n",
    "        Main transformer for the data. Can be used for processing on the whole data.\n",
    "\n",
    "        :param convert_cyclical: convert cyclical features into continuous\n",
    "        :param create_interactions: create interactions between features\n",
    "        \"\"\"\n",
    "\n",
    "        self.convert_cyclical = convert_cyclical\n",
    "        self.create_interactions = create_interactions\n",
    "        self.feats_for_interaction = None\n",
    "        self.n_interactions = n_interactions\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.create_interactions:\n",
    "            self.feats_for_interaction = [col for col in X.columns if 'sum' in col\n",
    "                                          or 'mean' in col or 'max' in col or 'std' in col\n",
    "                                          or 'attempt' in col]\n",
    "            self.feats_for_interaction1 = np.random.choice(self.feats_for_interaction, self.n_interactions)\n",
    "            self.feats_for_interaction2 = np.random.choice(self.feats_for_interaction, self.n_interactions)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "        if self.create_interactions:\n",
    "            for col1 in self.feats_for_interaction1:\n",
    "                for col2 in self.feats_for_interaction2:\n",
    "                    data[f'{col1}_int_{col2}'] = data[col1] * data[col2]\n",
    "\n",
    "        if self.convert_cyclical:\n",
    "            data['timestampHour'] = np.sin(2 * np.pi * data['timestampHour'] / 23.0)\n",
    "            data['timestampMonth'] = np.sin(2 * np.pi * data['timestampMonth'] / 23.0)\n",
    "            data['timestampWeek'] = np.sin(2 * np.pi * data['timestampWeek'] / 23.0)\n",
    "            data['timestampMinute'] = np.sin(2 * np.pi * data['timestampMinute'] / 23.0)\n",
    "\n",
    "#         data['installation_session_count'] = data.groupby(['installation_id'])['Clip'].transform('count')\n",
    "#         data['installation_duration_mean'] = data.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "#         data['installation_title_nunique'] = data.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "\n",
    "#         data['sum_event_code_count'] = data[['2000', '3010', '3110', '4070', '4090', '4030', '4035', '4021', '4020', '4010', '2080', '2083', '2040', '2020', '2030', '3021', '3121', '2050', '3020', '3120', '2060', '2070', '4031', '4025', '5000', '5010', '2081', '2025', '4022', '2035', '4040', '4100', '2010', '4110', '4045', '4095', '4220', '2075', '4230', '4235', '4080', '4050']].sum(axis=1)\n",
    "\n",
    "        # data['installation_event_code_count_mean'] = data.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, main_cat_features: list = None, num_cols: list = None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param main_cat_features:\n",
    "        :param num_cols:\n",
    "        \"\"\"\n",
    "        self.main_cat_features = main_cat_features\n",
    "        self.num_cols = num_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "#         self.num_cols = [col for col in X.columns if 'sum' in col or 'mean' in col or 'max' in col or 'std' in col\n",
    "#                          or 'attempt' in col]\n",
    "        \n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "#         for col in self.num_cols:\n",
    "#             data[f'{col}_to_mean'] = data[col] / data.groupby('installation_id')[col].transform('mean')\n",
    "#             data[f'{col}_to_std'] = data[col] / data.groupby('installation_id')[col].transform('std')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModel(object):\n",
    "    \"\"\"\n",
    "    A wrapper class for classification models.\n",
    "    It can be used for training and prediction.\n",
    "    Can plot feature importance and training progress (if relevant for model).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns: list = None, model_wrapper=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param original_columns:\n",
    "        :param model_wrapper:\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.model_wrapper = model_wrapper\n",
    "        \n",
    "        self.result_dict = {}\n",
    "        self.train_one_fold = False\n",
    "        self.preprocesser = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y,\n",
    "            X_holdout: pd.DataFrame = None, y_holdout=None,\n",
    "            folds=None,\n",
    "            params: dict = None,\n",
    "            eval_metric='rmse',\n",
    "            cols_to_drop: list = None,\n",
    "            preprocesser=None,\n",
    "            transformers: dict = None,\n",
    "            adversarial: bool = False,\n",
    "            plot: bool = True):\n",
    "        \"\"\"\n",
    "        Training the model.\n",
    "\n",
    "        :param X: training data\n",
    "        :param y: training target\n",
    "        :param X_holdout: holdout data\n",
    "        :param y_holdout: holdout target\n",
    "        :param folds: folds to split the data. If not defined, then model will be trained on the whole X\n",
    "        :param params: training parameters\n",
    "        :param eval_metric: metric for validataion\n",
    "        :param cols_to_drop: list of columns to drop (for example ID)\n",
    "        :param preprocesser: preprocesser class\n",
    "        :param transformers: transformer to use on folds\n",
    "        :param adversarial\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if folds is None:\n",
    "            folds = KFold(n_splits=3, random_state=42)\n",
    "            self.train_one_fold = True\n",
    "\n",
    "        self.columns = X.columns if self.columns is None else self.columns\n",
    "        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n",
    "        self.trained_transformers = {k: [] for k in transformers}\n",
    "        self.transformers = transformers\n",
    "        self.models = []\n",
    "        self.folds_dict = {}\n",
    "        self.eval_metric = eval_metric\n",
    "        n_target = 1\n",
    "        self.oof = np.zeros((len(X), n_target))\n",
    "        self.n_target = n_target\n",
    "\n",
    "        X = X[self.columns]\n",
    "        if X_holdout is not None:\n",
    "            X_holdout = X_holdout[self.columns]\n",
    "\n",
    "        if preprocesser is not None:\n",
    "            self.preprocesser = preprocesser\n",
    "            self.preprocesser.fit(X, y)\n",
    "            X = self.preprocesser.transform(X, y)\n",
    "            self.columns = X.columns.tolist()\n",
    "            if X_holdout is not None:\n",
    "                X_holdout = self.preprocesser.transform(X_holdout)\n",
    "\n",
    "        for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y, X['installation_id'])):\n",
    "\n",
    "            if X_holdout is not None:\n",
    "                X_hold = X_holdout.copy()\n",
    "            else:\n",
    "                X_hold = None\n",
    "            self.folds_dict[fold_n] = {}\n",
    "            if params['verbose']:\n",
    "                print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "            self.folds_dict[fold_n] = {}\n",
    "\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            if self.train_one_fold:\n",
    "                X_train = X[self.original_columns]\n",
    "                y_train = y\n",
    "                X_valid = None\n",
    "                y_valid = None\n",
    "\n",
    "            datasets = {'X_train': X_train, 'X_valid': X_valid, 'X_holdout': X_hold, 'y_train': y_train}\n",
    "            X_train, X_valid, X_hold = self.transform_(datasets, cols_to_drop)\n",
    "\n",
    "            self.folds_dict[fold_n]['columns'] = X_train.columns.tolist()\n",
    "\n",
    "            model = copy.deepcopy(self.model_wrapper)\n",
    "\n",
    "            if adversarial:\n",
    "                X_new1 = X_train.copy()\n",
    "                if X_valid is not None:\n",
    "                    X_new2 = X_valid.copy()\n",
    "                elif X_holdout is not None:\n",
    "                    X_new2 = X_holdout.copy()\n",
    "                X_new = pd.concat([X_new1, X_new2], axis=0)\n",
    "                y_new = np.hstack((np.zeros((X_new1.shape[0])), np.ones((X_new2.shape[0]))))\n",
    "                X_train, X_valid, y_train, y_valid = train_test_split(X_new, y_new)\n",
    "\n",
    "            model.fit(X_train, y_train, X_valid, y_valid, X_hold, y_holdout, params=params)\n",
    "\n",
    "            self.folds_dict[fold_n]['scores'] = model.best_score_\n",
    "            if self.oof.shape[0] != len(X):\n",
    "                self.oof = np.zeros((X.shape[0], self.oof.shape[1]))\n",
    "            if not adversarial:\n",
    "                self.oof[valid_index] = model.predict(X_valid).reshape(-1, n_target)\n",
    "\n",
    "            fold_importance = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)),\n",
    "                                           columns=['feature', 'importance'])\n",
    "            self.feature_importances = self.feature_importances.append(fold_importance)\n",
    "            self.models.append(model)\n",
    "\n",
    "        self.feature_importances['importance'] = self.feature_importances['importance'].astype(int)\n",
    "\n",
    "        # if params['verbose']:\n",
    "        self.calc_scores_()\n",
    "\n",
    "        if plot:\n",
    "            # print(classification_report(y, self.oof.argmax(1)))\n",
    "            fig, ax = plt.subplots(figsize=(16, 12))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            self.plot_feature_importance(top_n=20)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            self.plot_metric()\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.hist(y.values.reshape(-1, 1) - self.oof)\n",
    "            plt.title('Distribution of errors')\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.hist(self.oof)\n",
    "            plt.title('Distribution of oof predictions');\n",
    "\n",
    "    def transform_(self, datasets, cols_to_drop):\n",
    "        for name, transformer in self.transformers.items():\n",
    "            transformer.fit(datasets['X_train'], datasets['y_train'])\n",
    "            datasets['X_train'] = transformer.transform(datasets['X_train'])\n",
    "            if datasets['X_valid'] is not None:\n",
    "                datasets['X_valid'] = transformer.transform(datasets['X_valid'])\n",
    "            if datasets['X_holdout'] is not None:\n",
    "                datasets['X_holdout'] = transformer.transform(datasets['X_holdout'])\n",
    "            self.trained_transformers[name].append(transformer)\n",
    "        if cols_to_drop is not None:\n",
    "            cols_to_drop = [col for col in cols_to_drop if col in datasets['X_train'].columns]\n",
    "\n",
    "            datasets['X_train'] = datasets['X_train'].drop(cols_to_drop, axis=1)\n",
    "            if datasets['X_valid'] is not None:\n",
    "                datasets['X_valid'] = datasets['X_valid'].drop(cols_to_drop, axis=1)\n",
    "            if datasets['X_holdout'] is not None:\n",
    "                datasets['X_holdout'] = datasets['X_holdout'].drop(cols_to_drop, axis=1)\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "\n",
    "        return datasets['X_train'], datasets['X_valid'], datasets['X_holdout']\n",
    "\n",
    "    def calc_scores_(self):\n",
    "        print()\n",
    "        datasets = [k for k, v in [v['scores'] for k, v in self.folds_dict.items()][0].items() if len(v) > 0]\n",
    "        self.scores = {}\n",
    "        for d in datasets:\n",
    "            scores = [v['scores'][d][self.eval_metric] for k, v in self.folds_dict.items()]\n",
    "            print(f\"CV mean score on {d}: {np.mean(scores):.4f} +/- {np.std(scores):.4f} std.\")\n",
    "            self.scores[d] = np.mean(scores)\n",
    "\n",
    "    def predict(self, X_test, averaging: str = 'usual'):\n",
    "        \"\"\"\n",
    "        Make prediction\n",
    "\n",
    "        :param X_test:\n",
    "        :param averaging: method of averaging\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_prediction = np.zeros((X_test.shape[0], self.oof.shape[1]))\n",
    "        if self.preprocesser is not None:\n",
    "            X_test = self.preprocesser.transform(X_test)\n",
    "        for i in range(len(self.models)):\n",
    "            X_t = X_test.copy()\n",
    "            for name, transformers in self.trained_transformers.items():\n",
    "                X_t = transformers[i].transform(X_t)\n",
    "\n",
    "            if self.cols_to_drop is not None:\n",
    "                cols_to_drop = [col for col in self.cols_to_drop if col in X_t.columns]\n",
    "                X_t = X_t.drop(cols_to_drop, axis=1)\n",
    "            y_pred = self.models[i].predict(X_t[self.folds_dict[i]['columns']]).reshape(-1, full_prediction.shape[1])\n",
    "\n",
    "            # if case transformation changes the number of the rows\n",
    "            if full_prediction.shape[0] != len(y_pred):\n",
    "                full_prediction = np.zeros((y_pred.shape[0], self.oof.shape[1]))\n",
    "\n",
    "            if averaging == 'usual':\n",
    "                full_prediction += y_pred\n",
    "            elif averaging == 'rank':\n",
    "                full_prediction += pd.Series(y_pred).rank().values\n",
    "\n",
    "        return full_prediction / len(self.models)\n",
    "\n",
    "    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Plot default feature importance.\n",
    "\n",
    "        :param drop_null_importance: drop columns with null feature importance\n",
    "        :param top_n: show top n columns\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        top_feats = self.get_top_features(drop_null_importance, top_n)\n",
    "        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n",
    "        feature_importances['feature'] = feature_importances['feature'].astype(str)\n",
    "        top_feats = [str(i) for i in top_feats]\n",
    "        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats)\n",
    "        plt.title('Feature importances')\n",
    "\n",
    "    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Get top features by importance.\n",
    "\n",
    "        :param drop_null_importance:\n",
    "        :param top_n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n",
    "        if drop_null_importance:\n",
    "            grouped_feats = grouped_feats[grouped_feats != 0]\n",
    "        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n",
    "\n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "        Plot training progress.\n",
    "        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_evals_results = pd.DataFrame()\n",
    "        for model in self.models:\n",
    "            evals_result = pd.DataFrame()\n",
    "            for k in model.model.evals_result_.keys():\n",
    "                evals_result[k] = model.model.evals_result_[k][self.eval_metric]\n",
    "            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n",
    "            full_evals_results = full_evals_results.append(evals_result)\n",
    "\n",
    "        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n",
    "                                                                                            'variable': 'dataset'})\n",
    "        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n",
    "        plt.title('Training progress')\n",
    "\n",
    "        \n",
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cat_cols=None, drop_original: bool = False, encoder=OrdinalEncoder()):\n",
    "        \"\"\"\n",
    "        Categorical transformer. This is a wrapper for categorical encoders.\n",
    "\n",
    "        :param cat_cols:\n",
    "        :param drop_original:\n",
    "        :param encoder:\n",
    "        \"\"\"\n",
    "        self.cat_cols = cat_cols\n",
    "        self.drop_original = drop_original\n",
    "        self.encoder = encoder\n",
    "        self.default_encoder = OrdinalEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.cat_cols is None:\n",
    "            kinds = np.array([dt.kind for dt in X.dtypes])\n",
    "            is_cat = kinds == 'O'\n",
    "            self.cat_cols = list(X.columns[is_cat])\n",
    "        self.encoder.set_params(cols=self.cat_cols)\n",
    "        self.default_encoder.set_params(cols=self.cat_cols)\n",
    "\n",
    "        self.encoder.fit(X[self.cat_cols], y)\n",
    "        self.default_encoder.fit(X[self.cat_cols], y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "        new_cat_names = [f'{col}_encoded' for col in self.cat_cols]\n",
    "        encoded_data = self.encoder.transform(data[self.cat_cols])\n",
    "        if encoded_data.shape[1] == len(self.cat_cols):\n",
    "            data[new_cat_names] = encoded_data\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self.drop_original:\n",
    "            data = data.drop(self.cat_cols, axis=1)\n",
    "        else:\n",
    "            data[self.cat_cols] = self.default_encoder.transform(data[self.cat_cols])\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators':2000,\n",
    "#             'boosting_type': 'gbdt',\n",
    "#             'objective': 'regression',\n",
    "#             'metric': 'mae',\n",
    "#             'subsample': 0.7678,\n",
    "#             'subsample_freq': 1,\n",
    "#             'learning_rate': 0.08,\n",
    "#             'feature_fraction': 0.9,\n",
    "#             'max_depth': 17,\n",
    "#             'lambda_l1': 2,  \n",
    "#             'lambda_l2': 3,\n",
    "#             'verbose': 100,\n",
    "#             'early_stopping_rounds': 100, 'eval_metric': 'cappa'\n",
    "#             }\n",
    "# #0.7297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':20000,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'subsample': 0.7678,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.003,\n",
    "            'feature_fraction': 0.9,\n",
    "            'max_depth': 17,\n",
    "            'lambda_l1': 1,  \n",
    "            'lambda_l2': 1,\n",
    "            'verbose': 100,\n",
    "            'early_stopping_rounds': 100, 'eval_metric': 'cappa'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Wed Jan 22 10:25:25 2020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's l1: 1.05228\ttrain's cappa: 0.297679\tvalid's l1: 1.05513\tvalid's cappa: 0.302099\n",
      "[200]\ttrain's l1: 0.991256\ttrain's cappa: 0.341421\tvalid's l1: 0.997268\tvalid's cappa: 0.344124\n",
      "[300]\ttrain's l1: 0.942883\ttrain's cappa: 0.549706\tvalid's l1: 0.952499\tvalid's cappa: 0.524805\n",
      "[400]\ttrain's l1: 0.904274\ttrain's cappa: 0.599375\tvalid's l1: 0.917714\tvalid's cappa: 0.578231\n",
      "[500]\ttrain's l1: 0.874651\ttrain's cappa: 0.617747\tvalid's l1: 0.892532\tvalid's cappa: 0.589669\n",
      "[600]\ttrain's l1: 0.849691\ttrain's cappa: 0.631113\tvalid's l1: 0.872273\tvalid's cappa: 0.599969\n",
      "[700]\ttrain's l1: 0.828582\ttrain's cappa: 0.640284\tvalid's l1: 0.855555\tvalid's cappa: 0.607328\n",
      "[800]\ttrain's l1: 0.810871\ttrain's cappa: 0.647701\tvalid's l1: 0.842461\tvalid's cappa: 0.608477\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttrain's l1: 0.823274\ttrain's cappa: 0.642585\tvalid's l1: 0.851649\tvalid's cappa: 0.608999\n",
      "Fold 2 started at Wed Jan 22 10:25:52 2020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's l1: 1.05185\ttrain's cappa: 0.310176\tvalid's l1: 1.06536\tvalid's cappa: 0.286505\n",
      "[200]\ttrain's l1: 0.989464\ttrain's cappa: 0.352943\tvalid's l1: 1.00853\tvalid's cappa: 0.326034\n",
      "[300]\ttrain's l1: 0.941175\ttrain's cappa: 0.544801\tvalid's l1: 0.965831\tvalid's cappa: 0.51036\n",
      "[400]\ttrain's l1: 0.902313\ttrain's cappa: 0.600998\tvalid's l1: 0.931761\tvalid's cappa: 0.557718\n",
      "[500]\ttrain's l1: 0.872034\ttrain's cappa: 0.62168\tvalid's l1: 0.905992\tvalid's cappa: 0.573923\n",
      "[600]\ttrain's l1: 0.847263\ttrain's cappa: 0.635395\tvalid's l1: 0.886105\tvalid's cappa: 0.585264\n",
      "[700]\ttrain's l1: 0.826831\ttrain's cappa: 0.64414\tvalid's l1: 0.870196\tvalid's cappa: 0.595287\n",
      "[800]\ttrain's l1: 0.809154\ttrain's cappa: 0.651689\tvalid's l1: 0.856843\tvalid's cappa: 0.600692\n",
      "[900]\ttrain's l1: 0.794174\ttrain's cappa: 0.65691\tvalid's l1: 0.845946\tvalid's cappa: 0.603459\n",
      "[1000]\ttrain's l1: 0.781417\ttrain's cappa: 0.663952\tvalid's l1: 0.837462\tvalid's cappa: 0.607812\n",
      "[1100]\ttrain's l1: 0.770191\ttrain's cappa: 0.670326\tvalid's l1: 0.830756\tvalid's cappa: 0.609168\n",
      "Early stopping, best iteration is:\n",
      "[1066]\ttrain's l1: 0.7738\ttrain's cappa: 0.668318\tvalid's l1: 0.832814\tvalid's cappa: 0.610965\n",
      "Fold 3 started at Wed Jan 22 10:26:28 2020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's l1: 1.05732\ttrain's cappa: 0.319375\tvalid's l1: 1.03782\tvalid's cappa: 0.286453\n",
      "[200]\ttrain's l1: 0.993743\ttrain's cappa: 0.346908\tvalid's l1: 0.982455\tvalid's cappa: 0.3088\n",
      "[300]\ttrain's l1: 0.944422\ttrain's cappa: 0.549621\tvalid's l1: 0.940824\tvalid's cappa: 0.510191\n",
      "[400]\ttrain's l1: 0.905078\ttrain's cappa: 0.605472\tvalid's l1: 0.909494\tvalid's cappa: 0.558197\n",
      "[500]\ttrain's l1: 0.874489\ttrain's cappa: 0.623751\tvalid's l1: 0.886216\tvalid's cappa: 0.570283\n",
      "[600]\ttrain's l1: 0.849377\ttrain's cappa: 0.635497\tvalid's l1: 0.868169\tvalid's cappa: 0.57918\n",
      "[700]\ttrain's l1: 0.82817\ttrain's cappa: 0.644197\tvalid's l1: 0.85328\tvalid's cappa: 0.582343\n",
      "[800]\ttrain's l1: 0.809778\ttrain's cappa: 0.652898\tvalid's l1: 0.840771\tvalid's cappa: 0.587601\n",
      "[900]\ttrain's l1: 0.794461\ttrain's cappa: 0.658412\tvalid's l1: 0.831059\tvalid's cappa: 0.589319\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttrain's l1: 0.79834\ttrain's cappa: 0.656072\tvalid's l1: 0.833573\tvalid's cappa: 0.590349\n",
      "Fold 4 started at Wed Jan 22 10:27:00 2020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's l1: 1.04687\ttrain's cappa: 0.300812\tvalid's l1: 1.06397\tvalid's cappa: 0.270601\n",
      "[200]\ttrain's l1: 0.98323\ttrain's cappa: 0.372322\tvalid's l1: 1.00812\tvalid's cappa: 0.333995\n",
      "[300]\ttrain's l1: 0.933477\ttrain's cappa: 0.55934\tvalid's l1: 0.965267\tvalid's cappa: 0.511683\n",
      "[400]\ttrain's l1: 0.894722\ttrain's cappa: 0.606157\tvalid's l1: 0.933073\tvalid's cappa: 0.548794\n",
      "[500]\ttrain's l1: 0.864012\ttrain's cappa: 0.625664\tvalid's l1: 0.908415\tvalid's cappa: 0.564659\n",
      "[600]\ttrain's l1: 0.839025\ttrain's cappa: 0.638266\tvalid's l1: 0.889132\tvalid's cappa: 0.572898\n",
      "[700]\ttrain's l1: 0.818138\ttrain's cappa: 0.645155\tvalid's l1: 0.874174\tvalid's cappa: 0.577972\n",
      "[800]\ttrain's l1: 0.8003\ttrain's cappa: 0.652664\tvalid's l1: 0.862327\tvalid's cappa: 0.580544\n",
      "[900]\ttrain's l1: 0.785123\ttrain's cappa: 0.660068\tvalid's l1: 0.852798\tvalid's cappa: 0.581027\n",
      "[1000]\ttrain's l1: 0.772052\ttrain's cappa: 0.666576\tvalid's l1: 0.844999\tvalid's cappa: 0.585112\n",
      "[1100]\ttrain's l1: 0.760843\ttrain's cappa: 0.672634\tvalid's l1: 0.838983\tvalid's cappa: 0.586869\n",
      "[1200]\ttrain's l1: 0.750915\ttrain's cappa: 0.678517\tvalid's l1: 0.834121\tvalid's cappa: 0.587001\n",
      "[1300]\ttrain's l1: 0.742182\ttrain's cappa: 0.683829\tvalid's l1: 0.830251\tvalid's cappa: 0.588187\n",
      "[1400]\ttrain's l1: 0.734254\ttrain's cappa: 0.688507\tvalid's l1: 0.82695\tvalid's cappa: 0.589719\n",
      "[1500]\ttrain's l1: 0.727012\ttrain's cappa: 0.693758\tvalid's l1: 0.824214\tvalid's cappa: 0.591427\n",
      "[1600]\ttrain's l1: 0.720321\ttrain's cappa: 0.698305\tvalid's l1: 0.822006\tvalid's cappa: 0.593263\n",
      "[1700]\ttrain's l1: 0.714153\ttrain's cappa: 0.703741\tvalid's l1: 0.820137\tvalid's cappa: 0.593198\n",
      "Early stopping, best iteration is:\n",
      "[1607]\ttrain's l1: 0.719869\ttrain's cappa: 0.698739\tvalid's l1: 0.821858\tvalid's cappa: 0.594025\n",
      "Fold 5 started at Wed Jan 22 10:27:51 2020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's l1: 1.04916\ttrain's cappa: 0.308318\tvalid's l1: 1.07098\tvalid's cappa: 0.278961\n",
      "[200]\ttrain's l1: 0.985373\ttrain's cappa: 0.359871\tvalid's l1: 1.01641\tvalid's cappa: 0.308701\n",
      "[300]\ttrain's l1: 0.935206\ttrain's cappa: 0.567049\tvalid's l1: 0.974999\tvalid's cappa: 0.481892\n",
      "[400]\ttrain's l1: 0.894652\ttrain's cappa: 0.611678\tvalid's l1: 0.942379\tvalid's cappa: 0.530067\n",
      "[500]\ttrain's l1: 0.863343\ttrain's cappa: 0.630118\tvalid's l1: 0.91815\tvalid's cappa: 0.551246\n",
      "[600]\ttrain's l1: 0.837968\ttrain's cappa: 0.641476\tvalid's l1: 0.899064\tvalid's cappa: 0.564228\n",
      "[700]\ttrain's l1: 0.816912\ttrain's cappa: 0.648923\tvalid's l1: 0.884264\tvalid's cappa: 0.565451\n",
      "[800]\ttrain's l1: 0.79887\ttrain's cappa: 0.657448\tvalid's l1: 0.872219\tvalid's cappa: 0.567064\n",
      "[900]\ttrain's l1: 0.78344\ttrain's cappa: 0.663432\tvalid's l1: 0.862685\tvalid's cappa: 0.570708\n",
      "Early stopping, best iteration is:\n",
      "[892]\ttrain's l1: 0.784535\ttrain's cappa: 0.662258\tvalid's l1: 0.863356\tvalid's cappa: 0.572118\n",
      "\n",
      "CV mean score on train: 0.6656 +/- 0.0186 std.\n",
      "CV mean score on valid: 0.5953 +/- 0.0141 std.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = reduce_train['accuracy_group']\n",
    "n_fold = 5\n",
    "folds = GroupKFold(n_splits=n_fold)\n",
    "cols_to_drop = ['game_session', 'installation_id', 'timestamp', 'accuracy_group', 'timestampDate']\n",
    "mt = MainTransformer()\n",
    "ft = FeatureTransformer()\n",
    "transformers = {'ft': ft}\n",
    "regressor_model1 = RegressorModel(model_wrapper=LGBWrapper_regr())\n",
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]\n",
    "regressor_model1.fit(X=reduce_train, y=y, folds=folds, params=params, preprocesser=mt, transformers=transformers,\n",
    "                    eval_metric='cappa', cols_to_drop=cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy as sp\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to using current coefficients\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -qwk(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be bused for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 1.07 s, total: 19.8 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr1 = regressor_model1.predict(reduce_train)\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(pr1.reshape(-1,), y)\n",
    "coefficients = optR.coefficients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6178588145634945"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_preds = optR.predict(pr1.reshape(-1, ), coefficients)\n",
    "qwk(y, opt_preds)#0.7155119979142075\n",
    "#0.7227814975865664 for l1=2,l2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some coefficients calculated by me.\n",
    "pr1 = regressor_model1.predict(reduce_test)\n",
    "pr1[pr1 <= 1.12232214] = 0\n",
    "pr1[np.where(np.logical_and(pr1 > 1.12232214, pr1 <= 1.73925866))] = 1\n",
    "pr1[np.where(np.logical_and(pr1 > 1.73925866, pr1 <= 2.22506454))] = 2\n",
    "pr1[pr1 > 2.22506454] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(zf.open('sample_submission.csv'))\n",
    "sample_submission['accuracy_group'] = pr1.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['accuracy_group'].value_counts(normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
